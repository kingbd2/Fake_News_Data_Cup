{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Spacy \n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import en_core_web_md\n",
    "    \n",
    "# Other packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NLTK_functions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bff6ae691fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNLTK_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spaCy provides a variety of linguistic annotations to give you insights into a text’s grammatical structure. This includes the word types, like the parts of speech, and how the words are related to each other. For example, if you’re analyzing text, it makes a huge difference whether a noun is the subject of a sentence, or the object – or whether “google” is used as a verb, or refers to the website or company in a specific context.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NLTK_functions' is not defined"
     ]
    }
   ],
   "source": [
    "x = NLTK_functions(\"spaCy provides a variety of linguistic annotations to give you insights into a text’s grammatical structure. This includes the word types, like the parts of speech, and how the words are related to each other. For example, if you’re analyzing text, it makes a huge difference whether a noun is the subject of a sentence, or the object – or whether “google” is used as a verb, or refers to the website or company in a specific context.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-102a6ce3dcd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy_functions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0a5451d552a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"Apple is looking at buying U.K. startup for $1 billion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy_functions' is not defined"
     ]
    }
   ],
   "source": [
    "y = spacy_functions(u\"Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.K. startup for $1 billion"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.text_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "y.entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple True 7.1346846 False\n",
      "is True 4.890306 False\n",
      "looking True 5.4164834 False\n",
      "at True 6.0998254 False\n",
      "buying True 6.2184978 False\n",
      "U.K. True 6.626984 False\n",
      "startup True 6.779131 False\n",
      "for True 4.8435082 False\n",
      "$ True 7.748268 False\n",
      "1 True 5.269974 False\n",
      "billion True 8.310136 False\n"
     ]
    }
   ],
   "source": [
    "y.word_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLTK_functions:\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    # Filter text to remove punctuation and stopwords\n",
    "    def remove_stopwords(self):\n",
    "        text = re.sub(r'[^\\w\\s]', '', self.text)\n",
    "        text = word_tokenize(self.text)\n",
    "        return [w for w in text if not w in self.stop_words]\n",
    "\n",
    "    # Get word count of text with stopwords removed\n",
    "    def get_word_count(self):\n",
    "        word_list = self.remove_stopwords()\n",
    "        return len(word_list)\n",
    "\n",
    "    # Get token count of tokenized text\n",
    "    def get_token_count(self):\n",
    "        return len(word_tokenize(self.text))\n",
    "\n",
    "    # Get sentence count of tokenized text\n",
    "    def get_sentence_count(self):\n",
    "        sent_tokenize_list = sent_tokenize(self.text)\n",
    "        return len(sent_tokenize_list)\n",
    "\n",
    "    def get_brevity_score(self):\n",
    "        word_count_no_stopwords = self.get_word_count()\n",
    "        token_count = self.get_token_count()\n",
    "        return (word_count_no_stopwords / token_count)\n",
    "\n",
    "    def get_sentiment_nltk_vader(self):\n",
    "        tokens_list = word_tokenize(self.text)\n",
    "        sentence = ' '.join(word for word in tokens_list)\n",
    "        # print(sentence)\n",
    "        ss = self.sid.polarity_scores(sentence)\n",
    "        return [ss['pos'], ss['neg'], ss['neu'], ss['compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_append_feature(target_df, source_df_column, new_column_name, applied_function):\n",
    "    column_list = []\n",
    "    for text in target_df[source_df_column]:\n",
    "        column_list.append(applied_function(text))\n",
    "    target_df[new_column_name] = column_list\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r article_df article_df_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>[Trump, Supporter, Kicked, Pregnant, Muslim, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>[UW, Facts, Figures, University, WisconsinMadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>[US, Republic, Korea, Conclude, New, Special, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>[Kremlins, persistent, claim, expected, chemic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...   \n",
       "\n",
       "                                   text_no_stopwords  \n",
       "0  [Trump, Supporter, Kicked, Pregnant, Muslim, W...  \n",
       "1  [UW, Facts, Figures, University, WisconsinMadi...  \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...  \n",
       "3  [US, Republic, Korea, Conclude, New, Special, ...  \n",
       "4  [Kremlins, persistent, claim, expected, chemic...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trump Supporter “Kicked Pregnant Muslim Woman In Stomach Killing Unborn Twins”\\nA MAN was charged today charged over a race attack on a pregnant woman who later lost her unborn twin babies .\\n\\nDavid Gallacher, 37, is accused of assaulting the mum-to-be by kicking her in the stomach as she walked close to a mosque .\\n\\nGallacher has been bailed to appear at Milton Keynes Magistrates’ Court\\n\\nHe also allegedly attacked a man who tried to intervene during the incident in Milton Keynes, Bucks., last August.\\n\\nThe unnamed woman, who is a mum-of-four, was forced to flee her home in fear as a result of the assault.\\n\\nHer 40-year-old husband also had to give up his job as a taxi driver to stay home and reassure his traumatised wife.\\n\\nHe also allegedly attacked a man who tried to intervene during the incident in Milton Keynes, Bucks., last August.\\n\\nThe unnamed woman, who is a mum-of-four, was forced to flee her home in fear as a result of the assault.\\n\\nHer 40-year-old husband also had to give up his job as a taxi driver to stay home and reassure his traumatised wife.\\n\\nBefore they were scrubbed , social media pages, including Facebook indicated Gallacher was a “fan” of Donald Trump.\\n\\nGallacher was today charged with assault causing actual bodily harm, assault by beating and two counts of racially/religiously aggravated assault .\\n\\nHe has also been charged with three counts of assaulting a constable as they arrested a man in a separate incident on September 14 last year.\\n\\nGallacher, of no fixed abode, has been bailed to appear at Milton Keynes Magistrates’ Court on 14 March.\\n\\nEmail Addresses\\n\\nHair\\n\\nContacts\\n\\nBuck\\n\\nCharged\\n\\nCongress Courts\\n\\nDonalds\\n\\nDrinking\\n\\nDriver\\n\\nEmail Addresses\\n\\nHair Image used from similar incident in France, for illustrative purposes.\\n\\n.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.iloc(0)[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = NLTK_functions(article_df.iloc[0]['text']).remove_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    text_no_punc = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text_tokens = word_tokenize(text_no_punc)\n",
    "    return [w for w in text_tokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = create_append_feature(article_df, 'text', 'text_no_stopwords', remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>[Trump, Supporter, Kicked, Pregnant, Muslim, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>[UW, Facts, Figures, University, WisconsinMadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>[US, Republic, Korea, Conclude, New, Special, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>[Kremlins, persistent, claim, expected, chemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36159</td>\n",
       "      <td>59464</td>\n",
       "      <td>Was Obama’s $1.7 billion cash deal with Iran p...</td>\n",
       "      <td>[Was, Obamas, 17, billion, cash, deal, Iran, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36160</td>\n",
       "      <td>123044</td>\n",
       "      <td>Graeme Hart $265m superyacht Ulysses sold\\nUly...</td>\n",
       "      <td>[Graeme, Hart, 265m, superyacht, Ulysses, sold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36161</td>\n",
       "      <td>43414</td>\n",
       "      <td>New Hampshire\\nMedicaid-Marketplace Overview\\n...</td>\n",
       "      <td>[New, Hampshire, MedicaidMarketplace, Overview...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36162</td>\n",
       "      <td>15783</td>\n",
       "      <td>052314 mqspftexas\\n\\nEmails (excerpted), Micha...</td>\n",
       "      <td>[052314, mqspftexas, Emails, excerpted, Michae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36163</td>\n",
       "      <td>145502</td>\n",
       "      <td>Secondary Drinking Water Standards: Guidance f...</td>\n",
       "      <td>[Secondary, Drinking, Water, Standards, Guidan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0      106081  Trump Supporter “Kicked Pregnant Muslim Woman ...   \n",
       "1      129341  UW Facts and Figures – University of Wisconsin...   \n",
       "2      100963  Gun Control Advocates Target Peaceful Switzerl...   \n",
       "3       12200  U.S. and Republic of Korea Conclude New Specia...   \n",
       "4      128496  Kremlin's persistent claim of “expected chemic...   \n",
       "...       ...                                                ...   \n",
       "36159   59464  Was Obama’s $1.7 billion cash deal with Iran p...   \n",
       "36160  123044  Graeme Hart $265m superyacht Ulysses sold\\nUly...   \n",
       "36161   43414  New Hampshire\\nMedicaid-Marketplace Overview\\n...   \n",
       "36162   15783  052314 mqspftexas\\n\\nEmails (excerpted), Micha...   \n",
       "36163  145502  Secondary Drinking Water Standards: Guidance f...   \n",
       "\n",
       "                                       text_no_stopwords  \n",
       "0      [Trump, Supporter, Kicked, Pregnant, Muslim, W...  \n",
       "1      [UW, Facts, Figures, University, WisconsinMadi...  \n",
       "2      [Gun, Control, Advocates, Target, Peaceful, Sw...  \n",
       "3      [US, Republic, Korea, Conclude, New, Special, ...  \n",
       "4      [Kremlins, persistent, claim, expected, chemic...  \n",
       "...                                                  ...  \n",
       "36159  [Was, Obamas, 17, billion, cash, deal, Iran, p...  \n",
       "36160  [Graeme, Hart, 265m, superyacht, Ulysses, sold...  \n",
       "36161  [New, Hampshire, MedicaidMarketplace, Overview...  \n",
       "36162  [052314, mqspftexas, Emails, excerpted, Michae...  \n",
       "36163  [Secondary, Drinking, Water, Standards, Guidan...  \n",
       "\n",
       "[36164 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fake_News_Data_Cup",
   "language": "python",
   "name": "fake_news_data_cup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
