{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin documenting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import string, re\n",
    "# import pandas_profiling\n",
    "import itertools \n",
    "import pickle\n",
    "import local_modules.slack as slack\n",
    "from local_modules.Pickling import pickle_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pickle.load(open('test_features.pkl', 'rb'))['test_features']\n",
    "test_labels = pickle.load(open('test_labels.pkl', 'rb'))['test_labels']\n",
    "train_features = pickle.load(open('train_features.pkl', 'rb'))['train_features']\n",
    "train_labels = pickle.load(open('train_labels.pkl', 'rb'))['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eclf1': VotingClassifier(estimators=[('lr',\n",
       "                               LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                  dual=False, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='multinomial',\n",
       "                                                  n_jobs=None, penalty='l2',\n",
       "                                                  random_state=1, solver='lbfgs',\n",
       "                                                  tol=0.0001, verbose=0,\n",
       "                                                  warm_start=False)),\n",
       "                              ('rf',\n",
       "                               RandomForestClassifier(bootstrap=True,\n",
       "                                                      class_weight=None,\n",
       "                                                      criterion='g...\n",
       "                                                      max_features='auto',\n",
       "                                                      max_leaf_nodes=None,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1,\n",
       "                                                      min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators=50,\n",
       "                                                      n_jobs=None,\n",
       "                                                      oob_score=False,\n",
       "                                                      random_state=1, verbose=0,\n",
       "                                                      warm_start=False)),\n",
       "                              ('gnb',\n",
       "                               GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "                  flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                  weights=None),\n",
       " '_captured_io': {'stdout': <_io.StringIO at 0x7f247fa34690>,\n",
       "  'stderr': <_io.StringIO at 0x7f247fa34af0>,\n",
       "  'outputs': []},\n",
       " '_cell_md5': 'e81b7ebbac06a8a4acfb06dc29bb6800'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('voting_classifier.pkl', 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666,)\n",
      "(11666, 3111)\n",
      "(3889,)\n",
      "(3889, 3111)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_features.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model #1: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a random forest model on predicting fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(\"models/RandomForestClassifier.pkl\",\"wb\")\n",
    "pickle.dump(classifier, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial',\n",
    "                          random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(train_features, train_labels)\n",
    "print(eclf1.predict(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 2 0 0 0 2 0]\n",
      "12766    2\n",
      "6461     0\n",
      "9896     0\n",
      "13496    0\n",
      "5099     1\n",
      "9394     1\n",
      "1688     1\n",
      "8447     0\n",
      "720      1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eclf1.predict(train_features)[1:10])\n",
    "print(test_labels[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "pickle_item(\"models/test.pkl\", eclf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "\n",
    "\n",
    "np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
    "               eclf1.named_estimators_['lr'].predict(X))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "        voting='soft')\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "print(eclf2.predict(X))\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[\n",
    "       ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "       voting='soft', weights=[2,1,1],\n",
    "       flatten_transform=True)\n",
    "eclf3 = eclf3.fit(X, y)\n",
    "print(eclf3.predict(X))\n",
    "\n",
    "print(eclf3.transform(X).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force models using Hunga Bunga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_modules.hunga_bunga import HungaBungaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring criteria: accuracy\n",
      "--------------- model 1/15 ---------------\n",
      "SGDClassifier\n",
      "--------------- model 2/15 ---------------\n",
      "LogisticRegression\n",
      "--------------- model 3/15 ---------------\n",
      "Perceptron\n",
      "--------------- model 4/15 ---------------\n",
      "PassiveAggressiveClassifier\n",
      "--------------- model 5/15 ---------------\n",
      "MLPClassifier\n",
      "best score: 0.5143958868894601 time/clf: 2.819 seconds\n",
      "best params:\n",
      "{'activation': 'tanh',\n",
      " 'batch_size': 50,\n",
      " 'early_stopping': True,\n",
      " 'hidden_layer_sizes': (64,),\n",
      " 'learning_rate': 'invscaling',\n",
      " 'max_iter': 500}\n",
      "--------------- model 6/15 ---------------\n",
      "KMeans\n",
      "best score: 0.407369323050557 time/clf: 0.149 seconds\n",
      "best params:\n",
      "{'algorithm': 'elkan', 'init': 'random', 'n_clusters': 3}\n",
      "--------------- model 7/15 ---------------\n",
      "KNeighborsClassifier\n",
      "--------------- model 8/15 ---------------\n",
      "NearestCentroid\n",
      "best score: 0.4011139674378749 time/clf: 0.004 seconds\n",
      "best params:\n",
      "{'metric': 'manhattan', 'shrink_threshold': 2}\n",
      "--------------- model 9/15 ---------------\n",
      "RadiusNeighborsClassifier\n",
      "--------------- model 10/15 ---------------\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "clf = HungaBungaClassifier(brain=True)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-587007d1f8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azureml'"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"models/model.pkl\", 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fake_News_Data_Cup",
   "language": "python",
   "name": "fake_news_data_cup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
