{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prerequisite packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import string, re\n",
    "import itertools \n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "# import local_modules.slack as slack\n",
    "from local_modules.Pickling import pickle_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pickle.load(open('data/20191107-3_test_features.pkl', 'rb'))\n",
    "test_labels = pickle.load(open('data/20191107-3_test_labels.pkl', 'rb'))\n",
    "train_features = pickle.load(open('data/20191107-3_train_features.pkl', 'rb'))\n",
    "train_labels = pickle.load(open('data/20191107-3_train_labels.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666,)\n",
      "(11666, 13)\n",
      "(3889,)\n",
      "(3889, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_features.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a random forest model on predicting fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "pickle_item(\"models/20191107-3_RandomForestClassifier.pkl\", classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2: Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial',\n",
    "                          random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(train_features, train_labels)\n",
    "print(eclf1.predict(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 2 0]\n",
      "12766    2\n",
      "6461     0\n",
      "9896     0\n",
      "13496    0\n",
      "5099     1\n",
      "9394     1\n",
      "1688     1\n",
      "8447     0\n",
      "720      1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eclf1.predict(train_features)[1:10])\n",
    "print(test_labels[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "pickle_item(\"models/20191108-2_VotingClassifier.pkl\", eclf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "\n",
    "\n",
    "np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
    "               eclf1.named_estimators_['lr'].predict(X))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "        voting='soft')\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "print(eclf2.predict(X))\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[\n",
    "       ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "       voting='soft', weights=[2,1,1],\n",
    "       flatten_transform=True)\n",
    "eclf3 = eclf3.fit(X, y)\n",
    "print(eclf3.predict(X))\n",
    "\n",
    "print(eclf3.transform(X).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- learning_rate: step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "- max_depth: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "- subsample: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "- colsample_bytree: percentage of features used per tree. High value can lead to overfitting.\n",
    "- n_estimators: number of trees you want to build.\n",
    "- objective: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, binary:logistic for classification problems with probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
    "              nthread=None, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "pickle_item(\"models/20191107-3_XGBClassifier.pkl\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4: SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.8164183673469387, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
       "              l1_ratio=0.36734693877551017, learning_rate='constant',\n",
       "              loss='modified_huber', max_iter=1000, n_iter_no_change=5,\n",
       "              n_jobs=-1, penalty='none', power_t=0.8888888888888888,\n",
       "              random_state=None, shuffle=True, tol=0.01,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD_model = SGDClassifier(alpha=0.8164183673469387, class_weight=None, eta0=0.01,\n",
    "           fit_intercept=True, l1_ratio=0.36734693877551017,\n",
    "           learning_rate='constant', loss='modified_huber', max_iter=1000,\n",
    "           n_jobs=-1, penalty='none', power_t=0.8888888888888888,\n",
    "           random_state=None, tol=0.01)\n",
    "SGD_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "pickle_item(\"models/20191104_SGDClassifier.pkl\", SGD_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force models using Hunga Bunga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_modules.hunga_bunga import HungaBungaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring criteria: accuracy\n",
      "--------------- model 1/15 ---------------\n",
      "SGDClassifier\n",
      "--------------- model 2/15 ---------------\n",
      "LogisticRegression\n",
      "--------------- model 3/15 ---------------\n",
      "Perceptron\n",
      "--------------- model 4/15 ---------------\n",
      "PassiveAggressiveClassifier\n",
      "--------------- model 5/15 ---------------\n",
      "MLPClassifier\n",
      "best score: 0.5143958868894601 time/clf: 2.819 seconds\n",
      "best params:\n",
      "{'activation': 'tanh',\n",
      " 'batch_size': 50,\n",
      " 'early_stopping': True,\n",
      " 'hidden_layer_sizes': (64,),\n",
      " 'learning_rate': 'invscaling',\n",
      " 'max_iter': 500}\n",
      "--------------- model 6/15 ---------------\n",
      "KMeans\n",
      "best score: 0.407369323050557 time/clf: 0.149 seconds\n",
      "best params:\n",
      "{'algorithm': 'elkan', 'init': 'random', 'n_clusters': 3}\n",
      "--------------- model 7/15 ---------------\n",
      "KNeighborsClassifier\n",
      "--------------- model 8/15 ---------------\n",
      "NearestCentroid\n",
      "best score: 0.4011139674378749 time/clf: 0.004 seconds\n",
      "best params:\n",
      "{'metric': 'manhattan', 'shrink_threshold': 2}\n",
      "--------------- model 9/15 ---------------\n",
      "RadiusNeighborsClassifier\n",
      "--------------- model 10/15 ---------------\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "clf = HungaBungaClassifier(brain=True)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-587007d1f8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azureml'"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"models/model.pkl\", 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fake_News_Data_Cup",
   "language": "python",
   "name": "fake_news_data_cup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
