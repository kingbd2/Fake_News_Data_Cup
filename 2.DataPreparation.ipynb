{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string, re\n",
    "import pandas_profiling\n",
    "import pickle\n",
    "\n",
    "from local_modules.Pickling import pickle_item\n",
    "import local_modules.slack as slack\n",
    "import local_modules.DataPreparation as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingb\\projects\\poetry\\fake_news_data_cup\\.venv\\lib\\site-packages\\IPython\\config.py:13: ShimWarning: The `IPython.config` package has been deprecated since IPython 4.0. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "c:\\users\\kingb\\projects\\poetry\\fake_news_data_cup\\.venv\\src\\ipycache\\ipycache.py:17: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils.traitlets import Unicode\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipycache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skipped the cell's code and loaded variables article_df_enriched from file '/home/bking/Projects/pipenvs/Fake_News_Data_Cup/article_df_enriched.pkl'.]\n"
     ]
    }
   ],
   "source": [
    "%%cache article_df_enriched.pkl article_df_enriched\n",
    "%store -r article_df_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download NLTK corpora for stemming, tokenization, lemmatization\n",
    "For more information: https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get word count of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize, Stem, and Lemmatize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>brevity_score</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>nltk_pos_neg_neu_compound</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>nltk_neg</th>\n",
       "      <th>nltk_neu</th>\n",
       "      <th>nltk_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>225</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>[Trump, Supporter, “, Kicked, Pregnant, Muslim...</td>\n",
       "      <td>[0.027, 0.254, 0.719, -0.9973]</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>[UW, Facts, Figures, –, University, Wisconsin–...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>1055</td>\n",
       "      <td>1549</td>\n",
       "      <td>53</td>\n",
       "      <td>0.681085</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>[0.092, 0.101, 0.807, -0.8059]</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>202</td>\n",
       "      <td>284</td>\n",
       "      <td>8</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>[U.S., Republic, Korea, Conclude, New, Special...</td>\n",
       "      <td>[0.221, 0.01, 0.769, 0.9952]</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>437</td>\n",
       "      <td>679</td>\n",
       "      <td>18</td>\n",
       "      <td>0.643594</td>\n",
       "      <td>[Kremlin, 's, persistent, claim, “, expected, ...</td>\n",
       "      <td>[0.043, 0.13, 0.827, -0.9954]</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  word_count  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...         225   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...          50   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...        1055   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...         202   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...         437   \n",
       "\n",
       "   token_count  sentence_count  brevity_score  \\\n",
       "0          330              14       0.681818   \n",
       "1           69               2       0.724638   \n",
       "2         1549              53       0.681085   \n",
       "3          284               8       0.711268   \n",
       "4          679              18       0.643594   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  [Trump, Supporter, “, Kicked, Pregnant, Muslim...   \n",
       "1  [UW, Facts, Figures, –, University, Wisconsin–...   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...   \n",
       "3  [U.S., Republic, Korea, Conclude, New, Special...   \n",
       "4  [Kremlin, 's, persistent, claim, “, expected, ...   \n",
       "\n",
       "        nltk_pos_neg_neu_compound  nltk_pos  nltk_neg  nltk_neu  nltk_comp  \n",
       "0  [0.027, 0.254, 0.719, -0.9973]     0.027     0.254     0.719    -0.9973  \n",
       "1            [0.0, 0.0, 1.0, 0.0]     0.000     0.000     1.000     0.0000  \n",
       "2  [0.092, 0.101, 0.807, -0.8059]     0.092     0.101     0.807    -0.8059  \n",
       "3    [0.221, 0.01, 0.769, 0.9952]     0.221     0.010     0.769     0.9952  \n",
       "4   [0.043, 0.13, 0.827, -0.9954]     0.043     0.130     0.827    -0.9954  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = dp.remove_stopwords(article_df.iloc(0)[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run functions and append to dataframe for word count, token count, and brevity score\n",
    "dp.create_append_feature(article_df, 'text', 'claim_word_count', dp.get_word_count)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_token_count', dp.get_token_count)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_brevity_score', dp.get_brevity_score)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_filtered_text', dp.remove_stopwords)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_filtered_text', dp.get_sentiment_nltk_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Using NLTK vader\n",
    "http://www.nltk.org/howto/sentiment.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    neg: Negative\n",
    "    neu: Neutral\n",
    "    pos: Positive\n",
    "    compound: Compound (i.e. aggregated score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.create_append_feature(article_df, 'claim_sentiment_nltk', dp.get_sentiment_nltk_vader, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = article_df['filtered_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>brevity_score</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>nltk_pos_neg_neu_compound</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>nltk_neg</th>\n",
       "      <th>nltk_neu</th>\n",
       "      <th>nltk_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>225</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>[Trump, Supporter, “, Kicked, Pregnant, Muslim...</td>\n",
       "      <td>[0.027, 0.254, 0.719, -0.9973]</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>[UW, Facts, Figures, –, University, Wisconsin–...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>1055</td>\n",
       "      <td>1549</td>\n",
       "      <td>53</td>\n",
       "      <td>0.681085</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>[0.092, 0.101, 0.807, -0.8059]</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>202</td>\n",
       "      <td>284</td>\n",
       "      <td>8</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>[U.S., Republic, Korea, Conclude, New, Special...</td>\n",
       "      <td>[0.221, 0.01, 0.769, 0.9952]</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>437</td>\n",
       "      <td>679</td>\n",
       "      <td>18</td>\n",
       "      <td>0.643594</td>\n",
       "      <td>[Kremlin, 's, persistent, claim, “, expected, ...</td>\n",
       "      <td>[0.043, 0.13, 0.827, -0.9954]</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  word_count  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...         225   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...          50   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...        1055   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...         202   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...         437   \n",
       "\n",
       "   token_count  sentence_count  brevity_score  \\\n",
       "0          330              14       0.681818   \n",
       "1           69               2       0.724638   \n",
       "2         1549              53       0.681085   \n",
       "3          284               8       0.711268   \n",
       "4          679              18       0.643594   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  [Trump, Supporter, “, Kicked, Pregnant, Muslim...   \n",
       "1  [UW, Facts, Figures, –, University, Wisconsin–...   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...   \n",
       "3  [U.S., Republic, Korea, Conclude, New, Special...   \n",
       "4  [Kremlin, 's, persistent, claim, “, expected, ...   \n",
       "\n",
       "        nltk_pos_neg_neu_compound  nltk_pos  nltk_neg  nltk_neu  nltk_comp  \n",
       "0  [0.027, 0.254, 0.719, -0.9973]     0.027     0.254     0.719    -0.9973  \n",
       "1            [0.0, 0.0, 1.0, 0.0]     0.000     0.000     1.000     0.0000  \n",
       "2  [0.092, 0.101, 0.807, -0.8059]     0.092     0.101     0.807    -0.8059  \n",
       "3    [0.221, 0.01, 0.769, 0.9952]     0.221     0.010     0.769     0.9952  \n",
       "4   [0.043, 0.13, 0.827, -0.9954]     0.043     0.130     0.827    -0.9954  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_article_profile = article_df_enriched.profile_report(style={'full_width':True})\n",
    "enriched_article_profile.to_file(output_file=\"data_profiles/enriched_article_data_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store article_df_enriched for loading in Model Development\n",
    "article_df_enriched = article_df\n",
    "%store article_df_enriched "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training data preparation\n",
    "\n",
    "Here we will summarize the article data for each claim, building the training data for model development. \n",
    "Summary statistics include mean, variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.json\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame.from_records(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  \n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]  \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]  \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of related articles to training data\n",
    "train_df['num_related_articles']= train_df['related_articles'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cache data/train_df.pkl train_df\n",
    "%store -r train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile training data\n",
    "profile_train_df = train_df.profile_report(style={'full_width':True})\n",
    "profile_train_df.to_file(output_file=\"data_profiles/training_data_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fill out empty data for claimants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['claimant'].replace('', 'anon', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create claim sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15550</td>\n",
       "      <td>The omnibus spending bill has \"9,427 pork barr...</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>2009-02-25</td>\n",
       "      <td>2</td>\n",
       "      <td>[82947, 93503]</td>\n",
       "      <td>17137</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15551</td>\n",
       "      <td>Representative Maxine Waters said Muslims were...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>0</td>\n",
       "      <td>[103780, 104726, 126025]</td>\n",
       "      <td>17138</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.258, 0.742, -0.765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15552</td>\n",
       "      <td>\"We were not, I repeat, were not told that wat...</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2009-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>[11331, 68915, 2186, 2185, 88418, 81950]</td>\n",
       "      <td>17139</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15553</td>\n",
       "      <td>As of August 2017, members of the public could...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>2</td>\n",
       "      <td>[121353, 152864, 154411]</td>\n",
       "      <td>17140</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.134, 0.075, 0.791, 0.3612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15554</td>\n",
       "      <td>\"We don't get any of that information\" from th...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>1</td>\n",
       "      <td>[69545, 88929, 14698]</td>\n",
       "      <td>17141</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15555 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   claim         claimant  \\\n",
       "0      A line from George Orwell's novel 1984 predict...             anon   \n",
       "1      Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2      A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3      In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4      When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "...                                                  ...              ...   \n",
       "15550  The omnibus spending bill has \"9,427 pork barr...      John McCain   \n",
       "15551  Representative Maxine Waters said Muslims were...             anon   \n",
       "15552  \"We were not, I repeat, were not told that wat...     Nancy Pelosi   \n",
       "15553  As of August 2017, members of the public could...             anon   \n",
       "15554  \"We don't get any of that information\" from th...     Scott Walker   \n",
       "\n",
       "             date  label                            related_articles     id  \\\n",
       "0      2017-07-17      0            [122094, 122580, 130685, 134765]      0   \n",
       "1      2018-03-17      2                    [106868, 127320, 128060]      1   \n",
       "2      2018-07-18      1                    [132130, 132132, 149722]      4   \n",
       "3      2019-02-04      2                    [123254, 123418, 127464]      5   \n",
       "4      2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]      6   \n",
       "...           ...    ...                                         ...    ...   \n",
       "15550  2009-02-25      2                              [82947, 93503]  17137   \n",
       "15551  2017-06-06      0                    [103780, 104726, 126025]  17138   \n",
       "15552  2009-04-23      0    [11331, 68915, 2186, 2185, 88418, 81950]  17139   \n",
       "15553  2018-05-14      2                    [121353, 152864, 154411]  17140   \n",
       "15554  2016-12-23      1                       [69545, 88929, 14698]  17141   \n",
       "\n",
       "       num_related_articles            claim_nltk_sentiment  \n",
       "0                         4     [0.173, 0.0, 0.827, 0.3182]  \n",
       "1                         3  [0.133, 0.176, 0.691, -0.2023]  \n",
       "2                         3            [0.0, 0.0, 1.0, 0.0]  \n",
       "3                         3            [0.0, 0.0, 1.0, 0.0]  \n",
       "4                         6    [0.0, 0.344, 0.656, -0.9001]  \n",
       "...                     ...                             ...  \n",
       "15550                     2            [0.0, 0.0, 1.0, 0.0]  \n",
       "15551                     3     [0.0, 0.258, 0.742, -0.765]  \n",
       "15552                     6            [0.0, 0.0, 1.0, 0.0]  \n",
       "15553                     3   [0.134, 0.075, 0.791, 0.3612]  \n",
       "15554                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "\n",
       "[15555 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.create_append_feature(train_df, 'claim', 'claim_nltk_sentiment', dp.get_sentiment_nltk_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pickle.load(open('data/train_df.pkl', 'rb'))['train_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['num_related_articles']= train_df['related_articles'].apply(lambda x: len(x))\n",
    "train_df['claim_pos'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[0])\n",
    "train_df['claim_neg'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[1])\n",
    "train_df['claim_neu'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[2])\n",
    "train_df['claim_comp'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  claim_pos  claim_neg  \\\n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]      0.173      0.000   \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]      0.133      0.176   \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000   \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000   \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]      0.000      0.344   \n",
       "\n",
       "   claim_neu  claim_comp  \n",
       "0      0.827      0.3182  \n",
       "1      0.691     -0.2023  \n",
       "2      1.000      0.0000  \n",
       "3      1.000      0.0000  \n",
       "4      0.656     -0.9001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split data into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = train_df['label']\n",
    "features = train_df \\\n",
    "    .drop('claim_nltk_sentiment', axis = 1) \\\n",
    "    .drop('claim', axis = 1) \\\n",
    "    .drop('label', axis = 1) \\\n",
    "    .drop('related_articles', axis = 1) \\\n",
    "    .drop('id', axis = 1) \\\n",
    "    .drop('date', axis = 1) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          claimant  num_related_articles  claim_pos  claim_neg  claim_neu  \\\n",
       "0             anon                     4      0.173      0.000      0.827   \n",
       "1             anon                     3      0.133      0.176      0.691   \n",
       "2             anon                     3      0.000      0.000      1.000   \n",
       "3             anon                     3      0.000      0.000      1.000   \n",
       "4  Hillary Clinton                     6      0.000      0.344      0.656   \n",
       "\n",
       "   claim_comp  \n",
       "0      0.3182  \n",
       "1     -0.2023  \n",
       "2      0.0000  \n",
       "3      0.0000  \n",
       "4     -0.9001  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = features.to_csv(r'data/export_train_dataframe.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Standardization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to encode claimant? High dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = features.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = features.columns[categorical_feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder# instantiate labelencoder object\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claimant\n",
       "0      3081\n",
       "1      3081\n",
       "2      3081\n",
       "3      3081\n",
       "4      1121\n",
       "5      1650\n",
       "6      1327\n",
       "7      3081\n",
       "8      2385\n",
       "9      2001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply le on categorical feature columns\n",
    "features_categorical = features[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "features_categorical.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [6047]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3bb322366ba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6047\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kingb\\projects\\poetry\\fake_news_data_cup\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             raise ValueError(\n\u001b[1;32m--> 281\u001b[1;33m                     \"y contains previously unseen labels: %s\" % str(diff))\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [6047]"
     ]
    }
   ],
   "source": [
    "le.inverse_transform([6047])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claimant\n",
      "[3081]\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(features_categorical):\n",
    "    print (item)\n",
    "    \n",
    "print(features_categorical.iloc(0)[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder# instantiate OneHotEncoder\n",
    "ohe = OneHotEncoder(categories='auto', sparse=True ) \n",
    "# categorical_features = boolean mask for categorical columns\n",
    "# sparse = False output an array not sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative one hot encoding - using pandas.get_dummies\n",
    "features_ohe_pandas = pd.get_dummies(features, prefix=['claimant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "      <th>claimant_\"A Woman’s Right to Know Information Material”</th>\n",
       "      <th>claimant_\"suburban mom\" for Scott Taylor</th>\n",
       "      <th>claimant_@LagBeachAntifa9</th>\n",
       "      <th>claimant_@Sowellnomics</th>\n",
       "      <th>claimant_@WhiteHouse</th>\n",
       "      <th>...</th>\n",
       "      <th>claimant_religionmind.com</th>\n",
       "      <th>claimant_states-news.com</th>\n",
       "      <th>claimant_teaparty.org</th>\n",
       "      <th>claimant_therightwingportal.com</th>\n",
       "      <th>claimant_tmzbreaking</th>\n",
       "      <th>claimant_truthcommand.com</th>\n",
       "      <th>claimant_usaviralnews.info</th>\n",
       "      <th>claimant_whitehouse.gov</th>\n",
       "      <th>claimant_worldnewsdailyreport.com</th>\n",
       "      <th>claimant_Мikhail Aleksandrov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_related_articles  claim_pos  claim_neg  claim_neu  claim_comp  \\\n",
       "0                     4      0.173      0.000      0.827      0.3182   \n",
       "1                     3      0.133      0.176      0.691     -0.2023   \n",
       "2                     3      0.000      0.000      1.000      0.0000   \n",
       "3                     3      0.000      0.000      1.000      0.0000   \n",
       "4                     6      0.000      0.344      0.656     -0.9001   \n",
       "\n",
       "   claimant_\"A Woman’s Right to Know Information Material”  \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   claimant_\"suburban mom\" for Scott Taylor  claimant_@LagBeachAntifa9  \\\n",
       "0                                         0                          0   \n",
       "1                                         0                          0   \n",
       "2                                         0                          0   \n",
       "3                                         0                          0   \n",
       "4                                         0                          0   \n",
       "\n",
       "   claimant_@Sowellnomics  claimant_@WhiteHouse  ...  \\\n",
       "0                       0                     0  ...   \n",
       "1                       0                     0  ...   \n",
       "2                       0                     0  ...   \n",
       "3                       0                     0  ...   \n",
       "4                       0                     0  ...   \n",
       "\n",
       "   claimant_religionmind.com  claimant_states-news.com  claimant_teaparty.org  \\\n",
       "0                          0                         0                      0   \n",
       "1                          0                         0                      0   \n",
       "2                          0                         0                      0   \n",
       "3                          0                         0                      0   \n",
       "4                          0                         0                      0   \n",
       "\n",
       "   claimant_therightwingportal.com  claimant_tmzbreaking  \\\n",
       "0                                0                     0   \n",
       "1                                0                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "4                                0                     0   \n",
       "\n",
       "   claimant_truthcommand.com  claimant_usaviralnews.info  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   claimant_whitehouse.gov  claimant_worldnewsdailyreport.com  \\\n",
       "0                        0                                  0   \n",
       "1                        0                                  0   \n",
       "2                        0                                  0   \n",
       "3                        0                                  0   \n",
       "4                        0                                  0   \n",
       "\n",
       "   claimant_Мikhail Aleksandrov  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 3110 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ohe_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = features_ohe_pandas.to_csv(r'data/export_train_dataframe.csv', sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15555, 6047)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "S = csr_matrix(features_ohe)\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above manipulations one-hot encode claimant. Use the below if you do not want a sparse vector\n",
    "features_no_claimant = features.drop('claimant', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked=ssp.hstack( [S,features_no_claimant] ).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15555, 6052)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.array(labels).reshape(15555,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.    ,  0.    ,  0.    , ...,  0.827 ,  0.3182,  0.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  0.691 , -0.2023,  2.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  1.    ,  0.    ,  1.    ],\n",
       "        ...,\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  1.    ,  0.    ,  0.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  0.791 ,  0.3612,  2.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  1.    ,  0.    ,  1.    ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(stacked, labels_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/dataset.csv\", stacked, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative one hot encoding - using pandas.get_dummies\n",
    "features_ohe_pandas = pd.get_dummies(features, prefix=['claimant'])\n",
    "from sklearn import preprocessing# Get column names first\n",
    "names = features_ohe_pandas.columns# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()# Fit your data on the scaler object\n",
    "scaled_features = scaler.fit_transform(features_ohe_pandas)\n",
    "scaled_features = pd.DataFrame(scaled_features, columns=names)\n",
    "\n",
    "# scaled_labels = scaler.fit_transform(labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "      <th>claimant_\"A Woman’s Right to Know Information Material”</th>\n",
       "      <th>claimant_\"suburban mom\" for Scott Taylor</th>\n",
       "      <th>claimant_@LagBeachAntifa9</th>\n",
       "      <th>claimant_@Sowellnomics</th>\n",
       "      <th>claimant_@WhiteHouse</th>\n",
       "      <th>...</th>\n",
       "      <th>claimant_religionmind.com</th>\n",
       "      <th>claimant_states-news.com</th>\n",
       "      <th>claimant_teaparty.org</th>\n",
       "      <th>claimant_therightwingportal.com</th>\n",
       "      <th>claimant_tmzbreaking</th>\n",
       "      <th>claimant_truthcommand.com</th>\n",
       "      <th>claimant_usaviralnews.info</th>\n",
       "      <th>claimant_whitehouse.gov</th>\n",
       "      <th>claimant_worldnewsdailyreport.com</th>\n",
       "      <th>claimant_Мikhail Aleksandrov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.257627</td>\n",
       "      <td>1.215599</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>-0.166028</td>\n",
       "      <td>0.878091</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>0.770264</td>\n",
       "      <td>0.776614</td>\n",
       "      <td>-1.187540</td>\n",
       "      <td>-0.318251</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>0.146725</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>0.146725</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260793</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>2.243846</td>\n",
       "      <td>-1.450429</td>\n",
       "      <td>-1.922109</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>-0.776047</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>0.146725</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>1.492763</td>\n",
       "      <td>-0.804473</td>\n",
       "      <td>-1.611588</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15552</th>\n",
       "      <td>0.260793</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>0.146725</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15553</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>0.781397</td>\n",
       "      <td>-0.105472</td>\n",
       "      <td>-0.436428</td>\n",
       "      <td>0.976924</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15554</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>-0.710477</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>0.146725</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.008018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15555 rows × 3110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_related_articles  claim_pos  claim_neg  claim_neu  claim_comp  \\\n",
       "0                 -0.257627   1.215599  -0.760486  -0.166028    0.878091   \n",
       "1                 -0.516837   0.770264   0.776614  -1.187540   -0.318251   \n",
       "2                 -0.516837  -0.710477  -0.760486   1.133395    0.146725   \n",
       "3                 -0.516837  -0.710477  -0.760486   1.133395    0.146725   \n",
       "4                  0.260793  -0.710477   2.243846  -1.450429   -1.922109   \n",
       "...                     ...        ...        ...        ...         ...   \n",
       "15550             -0.776047  -0.710477  -0.760486   1.133395    0.146725   \n",
       "15551             -0.516837  -0.710477   1.492763  -0.804473   -1.611588   \n",
       "15552              0.260793  -0.710477  -0.760486   1.133395    0.146725   \n",
       "15553             -0.516837   0.781397  -0.105472  -0.436428    0.976924   \n",
       "15554             -0.516837  -0.710477  -0.760486   1.133395    0.146725   \n",
       "\n",
       "       claimant_\"A Woman’s Right to Know Information Material”  \\\n",
       "0                                              -0.008018         \n",
       "1                                              -0.008018         \n",
       "2                                              -0.008018         \n",
       "3                                              -0.008018         \n",
       "4                                              -0.008018         \n",
       "...                                                  ...         \n",
       "15550                                          -0.008018         \n",
       "15551                                          -0.008018         \n",
       "15552                                          -0.008018         \n",
       "15553                                          -0.008018         \n",
       "15554                                          -0.008018         \n",
       "\n",
       "       claimant_\"suburban mom\" for Scott Taylor  claimant_@LagBeachAntifa9  \\\n",
       "0                                     -0.008018                  -0.008018   \n",
       "1                                     -0.008018                  -0.008018   \n",
       "2                                     -0.008018                  -0.008018   \n",
       "3                                     -0.008018                  -0.008018   \n",
       "4                                     -0.008018                  -0.008018   \n",
       "...                                         ...                        ...   \n",
       "15550                                 -0.008018                  -0.008018   \n",
       "15551                                 -0.008018                  -0.008018   \n",
       "15552                                 -0.008018                  -0.008018   \n",
       "15553                                 -0.008018                  -0.008018   \n",
       "15554                                 -0.008018                  -0.008018   \n",
       "\n",
       "       claimant_@Sowellnomics  claimant_@WhiteHouse  ...  \\\n",
       "0                   -0.013889             -0.008018  ...   \n",
       "1                   -0.013889             -0.008018  ...   \n",
       "2                   -0.013889             -0.008018  ...   \n",
       "3                   -0.013889             -0.008018  ...   \n",
       "4                   -0.013889             -0.008018  ...   \n",
       "...                       ...                   ...  ...   \n",
       "15550               -0.013889             -0.008018  ...   \n",
       "15551               -0.013889             -0.008018  ...   \n",
       "15552               -0.013889             -0.008018  ...   \n",
       "15553               -0.013889             -0.008018  ...   \n",
       "15554               -0.013889             -0.008018  ...   \n",
       "\n",
       "       claimant_religionmind.com  claimant_states-news.com  \\\n",
       "0                      -0.008018                 -0.008018   \n",
       "1                      -0.008018                 -0.008018   \n",
       "2                      -0.008018                 -0.008018   \n",
       "3                      -0.008018                 -0.008018   \n",
       "4                      -0.008018                 -0.008018   \n",
       "...                          ...                       ...   \n",
       "15550                  -0.008018                 -0.008018   \n",
       "15551                  -0.008018                 -0.008018   \n",
       "15552                  -0.008018                 -0.008018   \n",
       "15553                  -0.008018                 -0.008018   \n",
       "15554                  -0.008018                 -0.008018   \n",
       "\n",
       "       claimant_teaparty.org  claimant_therightwingportal.com  \\\n",
       "0                  -0.008018                        -0.008018   \n",
       "1                  -0.008018                        -0.008018   \n",
       "2                  -0.008018                        -0.008018   \n",
       "3                  -0.008018                        -0.008018   \n",
       "4                  -0.008018                        -0.008018   \n",
       "...                      ...                              ...   \n",
       "15550              -0.008018                        -0.008018   \n",
       "15551              -0.008018                        -0.008018   \n",
       "15552              -0.008018                        -0.008018   \n",
       "15553              -0.008018                        -0.008018   \n",
       "15554              -0.008018                        -0.008018   \n",
       "\n",
       "       claimant_tmzbreaking  claimant_truthcommand.com  \\\n",
       "0                 -0.008018                  -0.008018   \n",
       "1                 -0.008018                  -0.008018   \n",
       "2                 -0.008018                  -0.008018   \n",
       "3                 -0.008018                  -0.008018   \n",
       "4                 -0.008018                  -0.008018   \n",
       "...                     ...                        ...   \n",
       "15550             -0.008018                  -0.008018   \n",
       "15551             -0.008018                  -0.008018   \n",
       "15552             -0.008018                  -0.008018   \n",
       "15553             -0.008018                  -0.008018   \n",
       "15554             -0.008018                  -0.008018   \n",
       "\n",
       "       claimant_usaviralnews.info  claimant_whitehouse.gov  \\\n",
       "0                       -0.008018                -0.008018   \n",
       "1                       -0.008018                -0.008018   \n",
       "2                       -0.008018                -0.008018   \n",
       "3                       -0.008018                -0.008018   \n",
       "4                       -0.008018                -0.008018   \n",
       "...                           ...                      ...   \n",
       "15550                   -0.008018                -0.008018   \n",
       "15551                   -0.008018                -0.008018   \n",
       "15552                   -0.008018                -0.008018   \n",
       "15553                   -0.008018                -0.008018   \n",
       "15554                   -0.008018                -0.008018   \n",
       "\n",
       "       claimant_worldnewsdailyreport.com  claimant_Мikhail Aleksandrov  \n",
       "0                              -0.013889                     -0.008018  \n",
       "1                              -0.013889                     -0.008018  \n",
       "2                              -0.013889                     -0.008018  \n",
       "3                              -0.013889                     -0.008018  \n",
       "4                              -0.013889                     -0.008018  \n",
       "...                                  ...                           ...  \n",
       "15550                          -0.013889                     -0.008018  \n",
       "15551                          -0.013889                     -0.008018  \n",
       "15552                          -0.013889                     -0.008018  \n",
       "15553                          -0.013889                     -0.008018  \n",
       "15554                          -0.013889                     -0.008018  \n",
       "\n",
       "[15555 rows x 3110 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split # Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(scaled_features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (11666, 3110)\n",
      "Training Labels Shape: (11666,)\n",
      "Testing Features Shape: (3889, 3110)\n",
      "Testing Labels Shape: (3889,)\n"
     ]
    }
   ],
   "source": [
    "# Make sure splitting was done right\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n",
      "Pickling completed\n",
      "Pickling completed\n",
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "# Pickle train_features, test_features, train_labels, test_labels\n",
    "pickle_item(\"data/20191103_train_features.pkl\", train_features)\n",
    "pickle_item(\"data/20191103_test_features.pkl\", test_features)\n",
    "pickle_item(\"data/20191103_train_labels.pkl\", train_labels)\n",
    "pickle_item(\"data/20191103_test_labels.pkl\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved variables 'train_features' to file 'C:\\Users\\kingb\\Projects\\poetry\\Fake_News_Data_Cup\\train_features.pkl'.]\n",
      "[Saved variables 'train_labels' to file 'C:\\Users\\kingb\\Projects\\poetry\\Fake_News_Data_Cup\\train_labels.pkl'.]\n",
      "[Saved variables 'test_features' to file 'C:\\Users\\kingb\\Projects\\poetry\\Fake_News_Data_Cup\\test_features.pkl'.]\n",
      "[Saved variables 'test_labels' to file 'C:\\Users\\kingb\\Projects\\poetry\\Fake_News_Data_Cup\\test_labels.pkl'.]\n"
     ]
    }
   ],
   "source": [
    "%%cache train_features.pkl train_features\n",
    "%%cache train_labels.pkl train_labels\n",
    "%%cache test_features.pkl test_features\n",
    "%%cache test_labels.pkl test_labels\n",
    "train_features   \n",
    "test_features\n",
    "test_labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv(\"data/2019-10-30-train_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df_enriched = pickle.load(open('data/article_df_enriched.pkl', 'rb'))\n",
    "article_df = pickle.load(open('data/article_df.pkl', 'rb'))\n",
    "train_df = pickle.load(open('data/train_df.pkl', 'rb'))\n",
    "train_dataframe = pickle.load(open('data/train_dataframe.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[\"train_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  \n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]  \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]  \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pickle.load(open('data/train_df.pkl', 'rb'))['train_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  \n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]  \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]  \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping claim_pos and claim_comp due to high correlation with claim_neg and claim_neu\n",
    "# train_df['num_related_articles']= train_df['related_articles'].apply(lambda x: len(x))\n",
    "train_df['claim_pos'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[0])\n",
    "train_df['claim_neg'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[1])\n",
    "train_df['claim_neu'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[2])\n",
    "train_df['claim_comp'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[3])\n",
    "# Labels are the values we want to predict\n",
    "labels = train_df['label']\n",
    "features = train_df \\\n",
    "    .drop('claim_nltk_sentiment', axis = 1) \\\n",
    "    .drop('claim', axis = 1) \\\n",
    "    .drop('label', axis = 1) \\\n",
    "    .drop('related_articles', axis = 1) \\\n",
    "    .drop('id', axis = 1) \\\n",
    "    .drop('date', axis = 1) \\\n",
    "    .drop('claim_pos', axis=1) \\\n",
    "    .drop('claim_comp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingb\\projects\\poetry\\fake_news_data_cup\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Feature reduction - see feature_importances.png\n",
    "important_claimants = ['Donald Trump', 'Bloggers', 'anon', 'Various websites', 'Viral image', 'multiple sources', 'Cyril Ramaphosa', 'Chain email', 'Facebook user', 'VIral meme']\n",
    "for i, item in enumerate(features['claimant']):\n",
    "    if item not in important_claimants:\n",
    "        features['claimant'].iloc[i]='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claimant  num_related_articles  claim_neg  claim_neu\n",
       "0     anon                     4      0.000      0.827\n",
       "1     anon                     3      0.176      0.691\n",
       "2     anon                     3      0.000      1.000\n",
       "3     anon                     3      0.000      1.000\n",
       "4    other                     6      0.344      0.656"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>brevity_score</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>nltk_pos_neg_neu_compound</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>nltk_neg</th>\n",
       "      <th>nltk_neu</th>\n",
       "      <th>nltk_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>225</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>[Trump, Supporter, “, Kicked, Pregnant, Muslim...</td>\n",
       "      <td>[0.027, 0.254, 0.719, -0.9973]</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>[UW, Facts, Figures, –, University, Wisconsin–...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>1055</td>\n",
       "      <td>1549</td>\n",
       "      <td>53</td>\n",
       "      <td>0.681085</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>[0.092, 0.101, 0.807, -0.8059]</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>202</td>\n",
       "      <td>284</td>\n",
       "      <td>8</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>[U.S., Republic, Korea, Conclude, New, Special...</td>\n",
       "      <td>[0.221, 0.01, 0.769, 0.9952]</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>437</td>\n",
       "      <td>679</td>\n",
       "      <td>18</td>\n",
       "      <td>0.643594</td>\n",
       "      <td>[Kremlin, 's, persistent, claim, “, expected, ...</td>\n",
       "      <td>[0.043, 0.13, 0.827, -0.9954]</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  word_count  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...         225   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...          50   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...        1055   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...         202   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...         437   \n",
       "\n",
       "   token_count  sentence_count  brevity_score  \\\n",
       "0          330              14       0.681818   \n",
       "1           69               2       0.724638   \n",
       "2         1549              53       0.681085   \n",
       "3          284               8       0.711268   \n",
       "4          679              18       0.643594   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  [Trump, Supporter, “, Kicked, Pregnant, Muslim...   \n",
       "1  [UW, Facts, Figures, –, University, Wisconsin–...   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...   \n",
       "3  [U.S., Republic, Korea, Conclude, New, Special...   \n",
       "4  [Kremlin, 's, persistent, claim, “, expected, ...   \n",
       "\n",
       "        nltk_pos_neg_neu_compound  nltk_pos  nltk_neg  nltk_neu  nltk_comp  \n",
       "0  [0.027, 0.254, 0.719, -0.9973]     0.027     0.254     0.719    -0.9973  \n",
       "1            [0.0, 0.0, 1.0, 0.0]     0.000     0.000     1.000     0.0000  \n",
       "2  [0.092, 0.101, 0.807, -0.8059]     0.092     0.101     0.807    -0.8059  \n",
       "3    [0.221, 0.01, 0.769, 0.9952]     0.221     0.010     0.769     0.9952  \n",
       "4   [0.043, 0.13, 0.827, -0.9954]     0.043     0.130     0.827    -0.9954  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df_enriched = article_df_enriched['article_df_enriched']\n",
    "article_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating article data to add to features\n",
    "# Only including positive and neutral sentiment, as neg and comp are highly correlated with pos and neu\n",
    "j = 0\n",
    "mean_neg = []\n",
    "mean_neu = []\n",
    "mean_brevity = []\n",
    "var_neg = []\n",
    "var_neu = []\n",
    "var_brevity = []\n",
    "for i, (claim) in enumerate(zip(train_df['train_df'].related_articles)):\n",
    "    brevity = np.zeros([len(claim[0]), 1])\n",
    "    neg = np.zeros([len(claim[0]), 1])\n",
    "    neu = np.zeros([len(claim[0]), 1])\n",
    "    for k, article_id in enumerate(claim[0]):\n",
    "        target = article_df_enriched.loc[article_df_enriched['id'] == article_id]\n",
    "        if target.empty:\n",
    "            continue\n",
    "        brevity[k-1, 0] = target['brevity_score'].values\n",
    "        neg[k-1, 0] = target['nltk_neg'].values  \n",
    "        neu[k-1, 0] = target['nltk_neu'].values\n",
    "    mean_neg.append(np.mean(neg))\n",
    "    mean_neu.append(np.mean(neu))\n",
    "    mean_brevity.append(np.mean(brevity))\n",
    "    var_neg.append(np.var(neg))\n",
    "    var_neu.append(np.var(neu))\n",
    "    var_brevity.append(np.var(brevity))\n",
    "\n",
    "features['mean_neg'] = mean_neg\n",
    "features['mean_neu'] = mean_neu\n",
    "features['mean_brevity'] = mean_brevity\n",
    "\n",
    "features['var_neg'] = var_neg\n",
    "features['var_neu'] = var_neu\n",
    "features['var_brevity'] = var_brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pickle.load(open('data/20191107_train_df.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  claim_pos  claim_neg  \\\n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]      0.173      0.000   \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]      0.133      0.176   \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000   \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000   \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]      0.000      0.344   \n",
       "\n",
       "   claim_neu  claim_comp  \n",
       "0      0.827      0.3182  \n",
       "1      0.691     -0.2023  \n",
       "2      1.000      0.0000  \n",
       "3      1.000      0.0000  \n",
       "4      0.656     -0.9001  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>mean_neg</th>\n",
       "      <th>mean_neu</th>\n",
       "      <th>mean_brevity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.619250</td>\n",
       "      <td>0.510241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.228895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.452712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.504333</td>\n",
       "      <td>0.433681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>0.116487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15552</th>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.145167</td>\n",
       "      <td>0.103074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15553</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.292667</td>\n",
       "      <td>0.214912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15554</th>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.055333</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.643421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15555 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      claimant  num_related_articles  claim_neg  claim_neu  mean_neg  \\\n",
       "0         anon                     4      0.000      0.827  0.061500   \n",
       "1         anon                     3      0.176      0.691  0.007000   \n",
       "2         anon                     3      0.000      1.000  0.010333   \n",
       "3         anon                     3      0.000      1.000  0.093000   \n",
       "4        other                     6      0.344      0.656  0.001500   \n",
       "...        ...                   ...        ...        ...       ...   \n",
       "15550    other                     2      0.000      1.000  0.000000   \n",
       "15551     anon                     3      0.258      0.742  0.000000   \n",
       "15552    other                     6      0.000      1.000  0.010167   \n",
       "15553     anon                     3      0.075      0.791  0.015667   \n",
       "15554    other                     3      0.000      1.000  0.055333   \n",
       "\n",
       "       mean_neu  mean_brevity  \n",
       "0      0.619250      0.510241  \n",
       "1      0.305000      0.228895  \n",
       "2      0.549000      0.452712  \n",
       "3      0.504333      0.433681  \n",
       "4      0.153167      0.116487  \n",
       "...         ...           ...  \n",
       "15550  0.000000      0.000000  \n",
       "15551  0.000000      0.000000  \n",
       "15552  0.145167      0.103074  \n",
       "15553  0.292667      0.214912  \n",
       "15554  0.854000      0.643421  \n",
       "\n",
       "[15555 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop('var_neg', axis = 1) \\\n",
    "    .drop('var_neu', axis=1) \\\n",
    "    .drop('var_brevity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('data/train_df.pkl', 'rb'))['train_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claimant  num_related_articles  claim_neg  claim_neu\n",
       "0     anon                     4      0.000      0.827\n",
       "1     anon                     3      0.176      0.691\n",
       "2     anon                     3      0.000      1.000\n",
       "3     anon                     3      0.000      1.000\n",
       "4    other                     6      0.344      0.656"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative one hot encoding - using pandas.get_dummies\n",
    "features_ohe_pandas = pd.get_dummies(features, prefix=['claimant'])\n",
    "from sklearn import preprocessing# Get column names first\n",
    "names = features_ohe_pandas.columns# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()# Fit your data on the scaler object\n",
    "scaled_features = scaler.fit_transform(features_ohe_pandas)\n",
    "scaled_features = pd.DataFrame(scaled_features, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claimant_Bloggers</th>\n",
       "      <th>claimant_Chain email</th>\n",
       "      <th>claimant_Cyril Ramaphosa</th>\n",
       "      <th>claimant_Donald Trump</th>\n",
       "      <th>claimant_Facebook user</th>\n",
       "      <th>claimant_Various websites</th>\n",
       "      <th>claimant_Viral image</th>\n",
       "      <th>claimant_anon</th>\n",
       "      <th>claimant_multiple sources</th>\n",
       "      <th>claimant_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.257627</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>-0.166028</td>\n",
       "      <td>-0.156528</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>-0.293413</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.082833</td>\n",
       "      <td>-0.090729</td>\n",
       "      <td>1.461104</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.102352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>0.776614</td>\n",
       "      <td>-1.187540</td>\n",
       "      <td>-0.156528</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>-0.293413</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.082833</td>\n",
       "      <td>-0.090729</td>\n",
       "      <td>1.461104</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.102352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>-0.156528</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>-0.293413</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.082833</td>\n",
       "      <td>-0.090729</td>\n",
       "      <td>1.461104</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.102352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.516837</td>\n",
       "      <td>-0.760486</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>-0.156528</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>-0.293413</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.082833</td>\n",
       "      <td>-0.090729</td>\n",
       "      <td>1.461104</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.102352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260793</td>\n",
       "      <td>2.243846</td>\n",
       "      <td>-1.450429</td>\n",
       "      <td>-0.156528</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>-0.293413</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.082833</td>\n",
       "      <td>-0.090729</td>\n",
       "      <td>-0.684414</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>0.907151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_related_articles  claim_neg  claim_neu  claimant_Bloggers  \\\n",
       "0             -0.257627  -0.760486  -0.166028          -0.156528   \n",
       "1             -0.516837   0.776614  -1.187540          -0.156528   \n",
       "2             -0.516837  -0.760486   1.133395          -0.156528   \n",
       "3             -0.516837  -0.760486   1.133395          -0.156528   \n",
       "4              0.260793   2.243846  -1.450429          -0.156528   \n",
       "\n",
       "   claimant_Chain email  claimant_Cyril Ramaphosa  claimant_Donald Trump  \\\n",
       "0             -0.067715                 -0.025363              -0.293413   \n",
       "1             -0.067715                 -0.025363              -0.293413   \n",
       "2             -0.067715                 -0.025363              -0.293413   \n",
       "3             -0.067715                 -0.025363              -0.293413   \n",
       "4             -0.067715                 -0.025363              -0.293413   \n",
       "\n",
       "   claimant_Facebook user  claimant_Various websites  claimant_Viral image  \\\n",
       "0               -0.067715                  -0.082833             -0.090729   \n",
       "1               -0.067715                  -0.082833             -0.090729   \n",
       "2               -0.067715                  -0.082833             -0.090729   \n",
       "3               -0.067715                  -0.082833             -0.090729   \n",
       "4               -0.067715                  -0.082833             -0.090729   \n",
       "\n",
       "   claimant_anon  claimant_multiple sources  claimant_other  \n",
       "0       1.461104                  -0.067235       -1.102352  \n",
       "1       1.461104                  -0.067235       -1.102352  \n",
       "2       1.461104                  -0.067235       -1.102352  \n",
       "3       1.461104                  -0.067235       -1.102352  \n",
       "4      -0.684414                  -0.067235        0.907151  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split # Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(scaled_features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = train_df.to_csv(r'data/20191107_train_df.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling completed\n",
      "Pickling completed\n",
      "Pickling completed\n",
      "Pickling completed\n"
     ]
    }
   ],
   "source": [
    "# Pickle train_features, test_features, train_labels, test_labels\n",
    "pickle_item(\"data/20191107-3_train_features.pkl\", train_features)\n",
    "pickle_item(\"data/20191107-3_test_features.pkl\", test_features)\n",
    "pickle_item(\"data/20191107-3_train_labels.pkl\", train_labels)\n",
    "pickle_item(\"data/20191107-3_test_labels.pkl\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666,)\n",
      "(11666, 13)\n",
      "(3889,)\n",
      "(3889, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_features.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemma = set([wnl.lemmatize(t) for t in tokens])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fake_News_Data_Cup",
   "language": "python",
   "name": "fake_news_data_cup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
