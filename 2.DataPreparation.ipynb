{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string, re\n",
    "import pandas_profiling\n",
    "import slack\n",
    "\n",
    "from progressbar import Bar, BouncingBar, Counter, ETA, \\\n",
    "    AdaptiveETA, FileTransferSpeed, FormatLabel, Percentage, \\\n",
    "    ProgressBar, ReverseBar, RotatingMarker, \\\n",
    "    SimpleProgress, Timer, UnknownLength\n",
    "pbar = ProgressBar()\n",
    "%store -r article_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download NLTK corpora for stemming, tokenization, lemmatization\n",
    "For more information: https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bking/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bking/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get word count of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize, Stem, and Lemmatize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...\n",
       "1  129341  UW Facts and Figures – University of Wisconsin...\n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...\n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...\n",
       "4  128496  Kremlin's persistent claim of “expected chemic..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter text to remove punctuation and stopwords\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "def remove_stopwords(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = word_tokenize(text)\n",
    "    return [w for w in text if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|############################################################|Time: 0:09:26\n"
     ]
    }
   ],
   "source": [
    "# a = list that gets populated with count of words from each article with stopwords removed.\n",
    "# b = list that gets populated with articles with stopwords removed.\n",
    "# c = list that gets populated with token count of each article.\n",
    "# d = list that gets populated with brevity score = word_count_no_stopwords / token_count\n",
    "# j = progress_indicator\n",
    "# pbar = progress_bar\n",
    "filtered_df = []\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "j = 0\n",
    "pbar = ProgressBar(widgets=[Percentage(), Bar(), ETA()], maxval=len(article_df)).start()\n",
    "for i, (article) in enumerate(zip(article_df.text)):\n",
    "    b.append(remove_stopwords(article[0]))\n",
    "    a.append(len(b[i]))\n",
    "    word_count_no_stopwords = a[i]\n",
    "    token_count = len(nltk.word_tokenize(article[0]))\n",
    "    brevity_score = word_count_no_stopwords / token_count\n",
    "    c.append(token_count)\n",
    "    d.append(brevity_score)\n",
    "    j += 1\n",
    "    limit = 0 \n",
    "    pbar.update(i+1)\n",
    "    if j%10000 == 0:\n",
    "        slack.SlackNotification('BK_slackbot', '%s / %s have completed' % (j, len(article_df)))\n",
    "pbar.finish()\n",
    "article_df['word_count_no_stop_words'] = a\n",
    "article_df['filtered_text'] = b\n",
    "article_df['token_count'] = c\n",
    "article_df['brevity_score'] = d\n",
    "slack.SlackNotification('BK_slackbot', 'All stopwords have been removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count_no_stop_words</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>brevity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>189</td>\n",
       "      <td>[Trump, Supporter, Kicked, Pregnant, Muslim, W...</td>\n",
       "      <td>330</td>\n",
       "      <td>0.572727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>40</td>\n",
       "      <td>[UW, Facts, Figures, University, WisconsinMadi...</td>\n",
       "      <td>69</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>909</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.586830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>173</td>\n",
       "      <td>[US, Republic, Korea, Conclude, New, Special, ...</td>\n",
       "      <td>284</td>\n",
       "      <td>0.609155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>351</td>\n",
       "      <td>[Kremlins, persistent, claim, expected, chemic...</td>\n",
       "      <td>679</td>\n",
       "      <td>0.516937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...   \n",
       "\n",
       "   word_count_no_stop_words  \\\n",
       "0                       189   \n",
       "1                        40   \n",
       "2                       909   \n",
       "3                       173   \n",
       "4                       351   \n",
       "\n",
       "                                       filtered_text  token_count  \\\n",
       "0  [Trump, Supporter, Kicked, Pregnant, Muslim, W...          330   \n",
       "1  [UW, Facts, Figures, University, WisconsinMadi...           69   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...         1549   \n",
       "3  [US, Republic, Korea, Conclude, New, Special, ...          284   \n",
       "4  [Kremlins, persistent, claim, expected, chemic...          679   \n",
       "\n",
       "   brevity_score  \n",
       "0       0.572727  \n",
       "1       0.579710  \n",
       "2       0.586830  \n",
       "3       0.609155  \n",
       "4       0.516937  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Using NLTK vader\n",
    "http://www.nltk.org/howto/sentiment.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    neg: Negative\n",
    "    neu: Neutral\n",
    "    pos: Positive\n",
    "    compound: Compound (i.e. aggregated score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = article_df['filtered_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|############################################################|Time: 0:07:14\n"
     ]
    }
   ],
   "source": [
    "# pos = list that gets populated with positive sentiment for each article with stopwords removed.\n",
    "# neg = list that gets populated with negative sentiment for each article with stopwords removed.\n",
    "# neu = list that gets populated with neutral sentiment for each article with stopwords removed.\n",
    "# comp = list that gets populated with compound score of senttiment for each article with stopwords removed.\n",
    "# j = progress_indicator\n",
    "# pbar = progress_bar\n",
    "j = 0\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "comp = []\n",
    "pbar = ProgressBar(widgets=[Percentage(), Bar(), ETA()], maxval=len(article_df)).start()\n",
    "for article in articles:\n",
    "    article_sentence = ' '.join(word for word in article)\n",
    "    ss = sid.polarity_scores(article_sentence)\n",
    "    pos.append(ss['pos'])\n",
    "    neg.append(ss['neg'])\n",
    "    neu.append(ss['neu'])\n",
    "    comp.append(ss['compound'])\n",
    "    pbar.update(i+1)\n",
    "    j += 1\n",
    "    if j%5000 == 0:\n",
    "        slack.SlackNotification('datacup', '%s / %s articles have been analyzed for sentiment.' % (j, len(article_df)))\n",
    "pbar.finish()\n",
    "article_df['pos'] = pos\n",
    "article_df['neg'] = neg\n",
    "article_df['neu'] = neu\n",
    "article_df['compound'] = comp\n",
    "slack.SlackNotification('datacup', 'All sentiment has been analyzed using the NLTK vader sentiment analysis method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count_no_stop_words</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>brevity_score</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>189</td>\n",
       "      <td>[Trump, Supporter, Kicked, Pregnant, Muslim, W...</td>\n",
       "      <td>330</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>40</td>\n",
       "      <td>[UW, Facts, Figures, University, WisconsinMadi...</td>\n",
       "      <td>69</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>909</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.586830</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.9666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>173</td>\n",
       "      <td>[US, Republic, Korea, Conclude, New, Special, ...</td>\n",
       "      <td>284</td>\n",
       "      <td>0.609155</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>351</td>\n",
       "      <td>[Kremlins, persistent, claim, expected, chemic...</td>\n",
       "      <td>679</td>\n",
       "      <td>0.516937</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.751</td>\n",
       "      <td>-0.9944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...   \n",
       "\n",
       "   word_count_no_stop_words  \\\n",
       "0                       189   \n",
       "1                        40   \n",
       "2                       909   \n",
       "3                       173   \n",
       "4                       351   \n",
       "\n",
       "                                       filtered_text  token_count  \\\n",
       "0  [Trump, Supporter, Kicked, Pregnant, Muslim, W...          330   \n",
       "1  [UW, Facts, Figures, University, WisconsinMadi...           69   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...         1549   \n",
       "3  [US, Republic, Korea, Conclude, New, Special, ...          284   \n",
       "4  [Kremlins, persistent, claim, expected, chemic...          679   \n",
       "\n",
       "   brevity_score    pos    neg    neu  compound  \n",
       "0       0.572727  0.037  0.338  0.625   -0.9971  \n",
       "1       0.579710  0.000  0.000  1.000    0.0000  \n",
       "2       0.586830  0.123  0.147  0.730   -0.9666  \n",
       "3       0.609155  0.288  0.014  0.698    0.9944  \n",
       "4       0.516937  0.057  0.192  0.751   -0.9944  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_df.to_csv(r'data/article_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = article_df.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(output_file=\"enriched_data_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'article_df_enriched' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Store article_df_enriched for loading in Model Development\n",
    "article_df_enriched = article_df\n",
    "%store article_df_enriched "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemma = set([wnl.lemmatize(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(tokens))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tags = nltk.pos_tag(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fake_News_Data_Cup",
   "language": "python",
   "name": "fake_news_data_cup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
