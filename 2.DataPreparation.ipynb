{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable article_df_enriched train_df\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string, re\n",
    "import pandas_profiling\n",
    "import local_modules.slack as slack\n",
    "import local_modules.DataPreparation as dp\n",
    "\n",
    "from progressbar import Bar, BouncingBar, Counter, ETA, \\\n",
    "    AdaptiveETA, FileTransferSpeed, FormatLabel, Percentage, \\\n",
    "    ProgressBar, ReverseBar, RotatingMarker, \\\n",
    "    SimpleProgress, Timer, UnknownLength\n",
    "pbar = ProgressBar()\n",
    "%store -r article_df article_df_enriched train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bking/virtualenvs/Fake_News_Data_Cup-bh3btNcR/lib/python3.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated since IPython 4.0. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/home/bking/virtualenvs/Fake_News_Data_Cup-bh3btNcR/lib/python3.7/site-packages/ipycache.py:17: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils.traitlets import Unicode\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipycache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skipped the cell's code and loaded variables article_df_enriched from file '/home/bking/Projects/pipenvs/Fake_News_Data_Cup/article_df_enriched.pkl'.]\n"
     ]
    }
   ],
   "source": [
    "%%cache article_df_enriched.pkl article_df_enriched\n",
    "%store -r article_df_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download NLTK corpora for stemming, tokenization, lemmatization\n",
    "For more information: https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get word count of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize, Stem, and Lemmatize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>brevity_score</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>nltk_pos_neg_neu_compound</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>nltk_neg</th>\n",
       "      <th>nltk_neu</th>\n",
       "      <th>nltk_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>225</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>[Trump, Supporter, “, Kicked, Pregnant, Muslim...</td>\n",
       "      <td>[0.027, 0.254, 0.719, -0.9973]</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>[UW, Facts, Figures, –, University, Wisconsin–...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>1055</td>\n",
       "      <td>1549</td>\n",
       "      <td>53</td>\n",
       "      <td>0.681085</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>[0.092, 0.101, 0.807, -0.8059]</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>202</td>\n",
       "      <td>284</td>\n",
       "      <td>8</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>[U.S., Republic, Korea, Conclude, New, Special...</td>\n",
       "      <td>[0.221, 0.01, 0.769, 0.9952]</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>437</td>\n",
       "      <td>679</td>\n",
       "      <td>18</td>\n",
       "      <td>0.643594</td>\n",
       "      <td>[Kremlin, 's, persistent, claim, “, expected, ...</td>\n",
       "      <td>[0.043, 0.13, 0.827, -0.9954]</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  word_count  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...         225   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...          50   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...        1055   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...         202   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...         437   \n",
       "\n",
       "   token_count  sentence_count  brevity_score  \\\n",
       "0          330              14       0.681818   \n",
       "1           69               2       0.724638   \n",
       "2         1549              53       0.681085   \n",
       "3          284               8       0.711268   \n",
       "4          679              18       0.643594   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  [Trump, Supporter, “, Kicked, Pregnant, Muslim...   \n",
       "1  [UW, Facts, Figures, –, University, Wisconsin–...   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...   \n",
       "3  [U.S., Republic, Korea, Conclude, New, Special...   \n",
       "4  [Kremlin, 's, persistent, claim, “, expected, ...   \n",
       "\n",
       "        nltk_pos_neg_neu_compound  nltk_pos  nltk_neg  nltk_neu  nltk_comp  \n",
       "0  [0.027, 0.254, 0.719, -0.9973]     0.027     0.254     0.719    -0.9973  \n",
       "1            [0.0, 0.0, 1.0, 0.0]     0.000     0.000     1.000     0.0000  \n",
       "2  [0.092, 0.101, 0.807, -0.8059]     0.092     0.101     0.807    -0.8059  \n",
       "3    [0.221, 0.01, 0.769, 0.9952]     0.221     0.010     0.769     0.9952  \n",
       "4   [0.043, 0.13, 0.827, -0.9954]     0.043     0.130     0.827    -0.9954  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = dp.remove_stopwords(article_df.iloc(0)[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run functions and append to dataframe for word count, token count, and brevity score\n",
    "dp.create_append_feature(article_df, 'text', 'claim_word_count', dp.get_word_count)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_token_count', dp.get_token_count)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_brevity_score', dp.get_brevity_score)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_filtered_text', dp.remove_stopwords)\n",
    "dp.create_append_feature(article_df, 'text', 'claim_filtered_text', dp.get_sentiment_nltk_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Using NLTK vader\n",
    "http://www.nltk.org/howto/sentiment.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    neg: Negative\n",
    "    neu: Neutral\n",
    "    pos: Positive\n",
    "    compound: Compound (i.e. aggregated score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.create_append_feature(article_df, 'claim_sentiment_nltk', dp.get_sentiment_nltk_vader, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = article_df['filtered_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>brevity_score</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>nltk_pos_neg_neu_compound</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>nltk_neg</th>\n",
       "      <th>nltk_neu</th>\n",
       "      <th>nltk_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>225</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>[Trump, Supporter, “, Kicked, Pregnant, Muslim...</td>\n",
       "      <td>[0.027, 0.254, 0.719, -0.9973]</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>[UW, Facts, Figures, –, University, Wisconsin–...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>1055</td>\n",
       "      <td>1549</td>\n",
       "      <td>53</td>\n",
       "      <td>0.681085</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>[0.092, 0.101, 0.807, -0.8059]</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>202</td>\n",
       "      <td>284</td>\n",
       "      <td>8</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>[U.S., Republic, Korea, Conclude, New, Special...</td>\n",
       "      <td>[0.221, 0.01, 0.769, 0.9952]</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>437</td>\n",
       "      <td>679</td>\n",
       "      <td>18</td>\n",
       "      <td>0.643594</td>\n",
       "      <td>[Kremlin, 's, persistent, claim, “, expected, ...</td>\n",
       "      <td>[0.043, 0.13, 0.827, -0.9954]</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  word_count  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...         225   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...          50   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...        1055   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...         202   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...         437   \n",
       "\n",
       "   token_count  sentence_count  brevity_score  \\\n",
       "0          330              14       0.681818   \n",
       "1           69               2       0.724638   \n",
       "2         1549              53       0.681085   \n",
       "3          284               8       0.711268   \n",
       "4          679              18       0.643594   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  [Trump, Supporter, “, Kicked, Pregnant, Muslim...   \n",
       "1  [UW, Facts, Figures, –, University, Wisconsin–...   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...   \n",
       "3  [U.S., Republic, Korea, Conclude, New, Special...   \n",
       "4  [Kremlin, 's, persistent, claim, “, expected, ...   \n",
       "\n",
       "        nltk_pos_neg_neu_compound  nltk_pos  nltk_neg  nltk_neu  nltk_comp  \n",
       "0  [0.027, 0.254, 0.719, -0.9973]     0.027     0.254     0.719    -0.9973  \n",
       "1            [0.0, 0.0, 1.0, 0.0]     0.000     0.000     1.000     0.0000  \n",
       "2  [0.092, 0.101, 0.807, -0.8059]     0.092     0.101     0.807    -0.8059  \n",
       "3    [0.221, 0.01, 0.769, 0.9952]     0.221     0.010     0.769     0.9952  \n",
       "4   [0.043, 0.13, 0.827, -0.9954]     0.043     0.130     0.827    -0.9954  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_article_profile = article_df_enriched.profile_report(style={'full_width':True})\n",
    "enriched_article_profile.to_file(output_file=\"data_profiles/enriched_article_data_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store article_df_enriched for loading in Model Development\n",
    "article_df_enriched = article_df\n",
    "%store article_df_enriched "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training data preparation\n",
    "\n",
    "Here we will summarize the article data for each claim, building the training data for model development. \n",
    "Summary statistics include mean, variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.json\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame.from_records(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  claim_pos  claim_neg  \n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]      0.173      0.000  \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]      0.133      0.176  \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000  \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000  \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]      0.000      0.344  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of related articles to training data\n",
    "train_df['num_related_articles']= train_df['related_articles'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cache data/train_df.pkl train_df\n",
    "%store -r train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile training data\n",
    "profile_train_df = train_df.profile_report(style={'full_width':True})\n",
    "profile_train_df.to_file(output_file=\"data_profiles/training_data_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fill out empty data for claimants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['claimant'].replace('', 'anon', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create claim sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15550</td>\n",
       "      <td>The omnibus spending bill has \"9,427 pork barr...</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>2009-02-25</td>\n",
       "      <td>2</td>\n",
       "      <td>[82947, 93503]</td>\n",
       "      <td>17137</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15551</td>\n",
       "      <td>Representative Maxine Waters said Muslims were...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>0</td>\n",
       "      <td>[103780, 104726, 126025]</td>\n",
       "      <td>17138</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.258, 0.742, -0.765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15552</td>\n",
       "      <td>\"We were not, I repeat, were not told that wat...</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2009-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>[11331, 68915, 2186, 2185, 88418, 81950]</td>\n",
       "      <td>17139</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15553</td>\n",
       "      <td>As of August 2017, members of the public could...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>2</td>\n",
       "      <td>[121353, 152864, 154411]</td>\n",
       "      <td>17140</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.134, 0.075, 0.791, 0.3612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15554</td>\n",
       "      <td>\"We don't get any of that information\" from th...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>1</td>\n",
       "      <td>[69545, 88929, 14698]</td>\n",
       "      <td>17141</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15555 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   claim         claimant  \\\n",
       "0      A line from George Orwell's novel 1984 predict...             anon   \n",
       "1      Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2      A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3      In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4      When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "...                                                  ...              ...   \n",
       "15550  The omnibus spending bill has \"9,427 pork barr...      John McCain   \n",
       "15551  Representative Maxine Waters said Muslims were...             anon   \n",
       "15552  \"We were not, I repeat, were not told that wat...     Nancy Pelosi   \n",
       "15553  As of August 2017, members of the public could...             anon   \n",
       "15554  \"We don't get any of that information\" from th...     Scott Walker   \n",
       "\n",
       "             date  label                            related_articles     id  \\\n",
       "0      2017-07-17      0            [122094, 122580, 130685, 134765]      0   \n",
       "1      2018-03-17      2                    [106868, 127320, 128060]      1   \n",
       "2      2018-07-18      1                    [132130, 132132, 149722]      4   \n",
       "3      2019-02-04      2                    [123254, 123418, 127464]      5   \n",
       "4      2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]      6   \n",
       "...           ...    ...                                         ...    ...   \n",
       "15550  2009-02-25      2                              [82947, 93503]  17137   \n",
       "15551  2017-06-06      0                    [103780, 104726, 126025]  17138   \n",
       "15552  2009-04-23      0    [11331, 68915, 2186, 2185, 88418, 81950]  17139   \n",
       "15553  2018-05-14      2                    [121353, 152864, 154411]  17140   \n",
       "15554  2016-12-23      1                       [69545, 88929, 14698]  17141   \n",
       "\n",
       "       num_related_articles            claim_nltk_sentiment  \n",
       "0                         4     [0.173, 0.0, 0.827, 0.3182]  \n",
       "1                         3  [0.133, 0.176, 0.691, -0.2023]  \n",
       "2                         3            [0.0, 0.0, 1.0, 0.0]  \n",
       "3                         3            [0.0, 0.0, 1.0, 0.0]  \n",
       "4                         6    [0.0, 0.344, 0.656, -0.9001]  \n",
       "...                     ...                             ...  \n",
       "15550                     2            [0.0, 0.0, 1.0, 0.0]  \n",
       "15551                     3     [0.0, 0.258, 0.742, -0.765]  \n",
       "15552                     6            [0.0, 0.0, 1.0, 0.0]  \n",
       "15553                     3   [0.134, 0.075, 0.791, 0.3612]  \n",
       "15554                     3            [0.0, 0.0, 1.0, 0.0]  \n",
       "\n",
       "[15555 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.create_append_feature(train_df, 'claim', 'claim_nltk_sentiment', dp.get_sentiment_nltk_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['num_related_articles']= train_df['related_articles'].apply(lambda x: len(x))\n",
    "train_df['claim_pos'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[0])\n",
    "train_df['claim_neg'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[1])\n",
    "train_df['claim_neu'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[2])\n",
    "train_df['claim_comp'] = train_df['claim_nltk_sentiment'].apply(lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_nltk_sentiment</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.173, 0.0, 0.827, 0.3182]</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.133, 0.176, 0.691, -0.2023]</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>anon</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.344, 0.656, -0.9001]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...             anon   \n",
       "1  Maine legislature candidate Leslie Gibson insu...             anon   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...             anon   \n",
       "3  In 1988 author Roald Dahl penned an open lette...             anon   \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   num_related_articles            claim_nltk_sentiment  claim_pos  claim_neg  \\\n",
       "0                     4     [0.173, 0.0, 0.827, 0.3182]      0.173      0.000   \n",
       "1                     3  [0.133, 0.176, 0.691, -0.2023]      0.133      0.176   \n",
       "2                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000   \n",
       "3                     3            [0.0, 0.0, 1.0, 0.0]      0.000      0.000   \n",
       "4                     6    [0.0, 0.344, 0.656, -0.9001]      0.000      0.344   \n",
       "\n",
       "   claim_neu  claim_comp  \n",
       "0      0.827      0.3182  \n",
       "1      0.691     -0.2023  \n",
       "2      1.000      0.0000  \n",
       "3      1.000      0.0000  \n",
       "4      0.656     -0.9001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split data into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = train_df['label']\n",
    "features = train_df \\\n",
    "    .drop('claim_nltk_sentiment', axis = 1) \\\n",
    "    .drop('claim', axis = 1) \\\n",
    "    .drop('label', axis = 1) \\\n",
    "    .drop('related_articles', axis = 1) \\\n",
    "    .drop('id', axis = 1) \\\n",
    "    .drop('date', axis = 1) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>anon</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>anon</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          claimant  num_related_articles  claim_pos  claim_neg  claim_neu  \\\n",
       "0             anon                     4      0.173      0.000      0.827   \n",
       "1             anon                     3      0.133      0.176      0.691   \n",
       "2             anon                     3      0.000      0.000      1.000   \n",
       "3             anon                     3      0.000      0.000      1.000   \n",
       "4  Hillary Clinton                     6      0.000      0.344      0.656   \n",
       "\n",
       "   claim_comp  \n",
       "0      0.3182  \n",
       "1     -0.2023  \n",
       "2      0.0000  \n",
       "3      0.0000  \n",
       "4     -0.9001  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = features.to_csv(r'data/export_train_dataframe.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Standardization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to encode claimant? High dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = features.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = features.columns[categorical_feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder# instantiate labelencoder object\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claimant\n",
       "0      3081\n",
       "1      3081\n",
       "2      3081\n",
       "3      3081\n",
       "4      1121\n",
       "5      1650\n",
       "6      1327\n",
       "7      3081\n",
       "8      2385\n",
       "9      2001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply le on categorical feature columns\n",
    "features[categorical_cols] = features[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "features[categorical_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder# instantiate OneHotEncoder\n",
    "ohe = OneHotEncoder(categories='auto', sparse=True ) \n",
    "# categorical_features = boolean mask for categorical columns\n",
    "# sparse = False output an array not sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative one hot encoding - using pandas.get_dummies\n",
    "features_ohe_pandas = pd.get_dummies(features, prefix=['claimant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ohe_pandas['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_related_articles</th>\n",
       "      <th>claim_pos</th>\n",
       "      <th>claim_neg</th>\n",
       "      <th>claim_neu</th>\n",
       "      <th>claim_comp</th>\n",
       "      <th>labels</th>\n",
       "      <th>claimant_\"A Woman’s Right to Know Information Material”</th>\n",
       "      <th>claimant_\"suburban mom\" for Scott Taylor</th>\n",
       "      <th>claimant_@LagBeachAntifa9</th>\n",
       "      <th>claimant_@Sowellnomics</th>\n",
       "      <th>...</th>\n",
       "      <th>claimant_religionmind.com</th>\n",
       "      <th>claimant_states-news.com</th>\n",
       "      <th>claimant_teaparty.org</th>\n",
       "      <th>claimant_therightwingportal.com</th>\n",
       "      <th>claimant_tmzbreaking</th>\n",
       "      <th>claimant_truthcommand.com</th>\n",
       "      <th>claimant_usaviralnews.info</th>\n",
       "      <th>claimant_whitehouse.gov</th>\n",
       "      <th>claimant_worldnewsdailyreport.com</th>\n",
       "      <th>claimant_Мikhail Aleksandrov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_related_articles  claim_pos  claim_neg  claim_neu  claim_comp  labels  \\\n",
       "0                     4      0.173      0.000      0.827      0.3182       0   \n",
       "1                     3      0.133      0.176      0.691     -0.2023       2   \n",
       "2                     3      0.000      0.000      1.000      0.0000       1   \n",
       "3                     3      0.000      0.000      1.000      0.0000       2   \n",
       "4                     6      0.000      0.344      0.656     -0.9001       2   \n",
       "\n",
       "   claimant_\"A Woman’s Right to Know Information Material”  \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   claimant_\"suburban mom\" for Scott Taylor  claimant_@LagBeachAntifa9  \\\n",
       "0                                         0                          0   \n",
       "1                                         0                          0   \n",
       "2                                         0                          0   \n",
       "3                                         0                          0   \n",
       "4                                         0                          0   \n",
       "\n",
       "   claimant_@Sowellnomics  ...  claimant_religionmind.com  \\\n",
       "0                       0  ...                          0   \n",
       "1                       0  ...                          0   \n",
       "2                       0  ...                          0   \n",
       "3                       0  ...                          0   \n",
       "4                       0  ...                          0   \n",
       "\n",
       "   claimant_states-news.com  claimant_teaparty.org  \\\n",
       "0                         0                      0   \n",
       "1                         0                      0   \n",
       "2                         0                      0   \n",
       "3                         0                      0   \n",
       "4                         0                      0   \n",
       "\n",
       "   claimant_therightwingportal.com  claimant_tmzbreaking  \\\n",
       "0                                0                     0   \n",
       "1                                0                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "4                                0                     0   \n",
       "\n",
       "   claimant_truthcommand.com  claimant_usaviralnews.info  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   claimant_whitehouse.gov  claimant_worldnewsdailyreport.com  \\\n",
       "0                        0                                  0   \n",
       "1                        0                                  0   \n",
       "2                        0                                  0   \n",
       "3                        0                                  0   \n",
       "4                        0                                  0   \n",
       "\n",
       "   claimant_Мikhail Aleksandrov  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 3111 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ohe_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = features_ohe_pandas.to_csv(r'data/export_train_dataframe.csv', sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ohe = ohe.fit_transform(features) # It returns an numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15555, 6047)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "S = csr_matrix(features_ohe)\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above manipulations one-hot encode claimant. Use the below if you do not want a sparse vector\n",
    "features_no_claimant = features.drop('claimant', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked=ssp.hstack( [S,features_no_claimant] ).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15555, 6052)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.array(labels).reshape(15555,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.    ,  0.    ,  0.    , ...,  0.827 ,  0.3182,  0.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  0.691 , -0.2023,  2.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  1.    ,  0.    ,  1.    ],\n",
       "        ...,\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  1.    ,  0.    ,  0.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  0.791 ,  0.3612,  2.    ],\n",
       "        [ 0.    ,  0.    ,  0.    , ...,  1.    ,  0.    ,  1.    ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(stacked, labels_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/dataset.csv\", stacked, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-aa5dc1020b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;31m# Get column names first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;31m# Create the Scaler object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Fit your data on the scaler object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'matrix' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing# Get column names first\n",
    "names = stacked.columns# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()# Fit your data on the scaler object\n",
    "scaled_features = scaler.fit_transform(stacked)\n",
    "scaled_features = pd.DataFrame(scaled_features, columns=names)\n",
    "\n",
    "# scaled_labels = scaler.fit_transform(labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split # Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(stacked, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (11666, 6052)\n",
      "Training Labels Shape: (11666,)\n",
      "Testing Features Shape: (3889, 6052)\n",
      "Testing Labels Shape: (3889,)\n"
     ]
    }
   ],
   "source": [
    "# Make sure splitting was done right\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_features' (matrix)\n",
      "Stored 'test_features' (matrix)\n",
      "Stored 'train_labels' (Series)\n",
      "Stored 'test_labels' (Series)\n"
     ]
    }
   ],
   "source": [
    "# Store data for loading in Model Development\n",
    "%store train_features   \n",
    "%store test_features\n",
    "%store train_labels\n",
    "%store test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemma = set([wnl.lemmatize(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(tokens))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tags = nltk.pos_tag(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
