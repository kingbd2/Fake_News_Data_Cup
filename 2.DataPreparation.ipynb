{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string, re\n",
    "import pandas_profiling\n",
    "import local_modules.slack as slack\n",
    "\n",
    "from progressbar import Bar, BouncingBar, Counter, ETA, \\\n",
    "    AdaptiveETA, FileTransferSpeed, FormatLabel, Percentage, \\\n",
    "    ProgressBar, ReverseBar, RotatingMarker, \\\n",
    "    SimpleProgress, Timer, UnknownLength\n",
    "pbar = ProgressBar()\n",
    "%store -r article_df article_df_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download NLTK corpora for stemming, tokenization, lemmatization\n",
    "For more information: https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bking/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bking/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get word count of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize, Stem, and Lemmatize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...\n",
       "1  129341  UW Facts and Figures – University of Wisconsin...\n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...\n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...\n",
       "4  128496  Kremlin's persistent claim of “expected chemic..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter text to remove punctuation and stopwords\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "def remove_stopwords(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = word_tokenize(text)\n",
    "    return [w for w in text if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|############################################################|Time: 0:09:26\n"
     ]
    }
   ],
   "source": [
    "# a = list that gets populated with count of words from each article with stopwords removed.\n",
    "# b = list that gets populated with articles with stopwords removed.\n",
    "# c = list that gets populated with token count of each article.\n",
    "# d = list that gets populated with brevity score = word_count_no_stopwords / token_count\n",
    "# j = progress_indicator\n",
    "# pbar = progress_bar\n",
    "filtered_df = []\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "j = 0\n",
    "pbar = ProgressBar(widgets=[Percentage(), Bar(), ETA()], maxval=len(article_df)).start()\n",
    "for i, (article) in enumerate(zip(article_df.text)):\n",
    "    b.append(remove_stopwords(article[0]))\n",
    "    a.append(len(b[i]))\n",
    "    word_count_no_stopwords = a[i]\n",
    "    token_count = len(nltk.word_tokenize(article[0]))\n",
    "    brevity_score = word_count_no_stopwords / token_count\n",
    "    c.append(token_count)\n",
    "    d.append(brevity_score)\n",
    "    j += 1\n",
    "    limit = 0 \n",
    "    pbar.update(i+1)\n",
    "    if j%10000 == 0:\n",
    "        slack.SlackNotification('BK_slackbot', '%s / %s have completed' % (j, len(article_df)))\n",
    "pbar.finish()\n",
    "article_df['word_count_no_stop_words'] = a\n",
    "article_df['filtered_text'] = b\n",
    "article_df['token_count'] = c\n",
    "article_df['brevity_score'] = d\n",
    "slack.SlackNotification('BK_slackbot', 'All stopwords have been removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count_no_stop_words</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>brevity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "      <td>189</td>\n",
       "      <td>[Trump, Supporter, Kicked, Pregnant, Muslim, W...</td>\n",
       "      <td>330</td>\n",
       "      <td>0.572727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "      <td>40</td>\n",
       "      <td>[UW, Facts, Figures, University, WisconsinMadi...</td>\n",
       "      <td>69</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "      <td>909</td>\n",
       "      <td>[Gun, Control, Advocates, Target, Peaceful, Sw...</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.586830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "      <td>173</td>\n",
       "      <td>[US, Republic, Korea, Conclude, New, Special, ...</td>\n",
       "      <td>284</td>\n",
       "      <td>0.609155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "      <td>351</td>\n",
       "      <td>[Kremlins, persistent, claim, expected, chemic...</td>\n",
       "      <td>679</td>\n",
       "      <td>0.516937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...   \n",
       "1  129341  UW Facts and Figures – University of Wisconsin...   \n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...   \n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...   \n",
       "4  128496  Kremlin's persistent claim of “expected chemic...   \n",
       "\n",
       "   word_count_no_stop_words  \\\n",
       "0                       189   \n",
       "1                        40   \n",
       "2                       909   \n",
       "3                       173   \n",
       "4                       351   \n",
       "\n",
       "                                       filtered_text  token_count  \\\n",
       "0  [Trump, Supporter, Kicked, Pregnant, Muslim, W...          330   \n",
       "1  [UW, Facts, Figures, University, WisconsinMadi...           69   \n",
       "2  [Gun, Control, Advocates, Target, Peaceful, Sw...         1549   \n",
       "3  [US, Republic, Korea, Conclude, New, Special, ...          284   \n",
       "4  [Kremlins, persistent, claim, expected, chemic...          679   \n",
       "\n",
       "   brevity_score  \n",
       "0       0.572727  \n",
       "1       0.579710  \n",
       "2       0.586830  \n",
       "3       0.609155  \n",
       "4       0.516937  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Using NLTK vader\n",
    "http://www.nltk.org/howto/sentiment.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    neg: Negative\n",
    "    neu: Neutral\n",
    "    pos: Positive\n",
    "    compound: Compound (i.e. aggregated score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = article_df['filtered_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|############################################################|Time: 0:07:14\n"
     ]
    }
   ],
   "source": [
    "# pos = list that gets populated with positive sentiment for each article with stopwords removed.\n",
    "# neg = list that gets populated with negative sentiment for each article with stopwords removed.\n",
    "# neu = list that gets populated with neutral sentiment for each article with stopwords removed.\n",
    "# comp = list that gets populated with compound score of sentiment for each article with stopwords removed.\n",
    "# j = progress_indicator\n",
    "# pbar = progress_bar\n",
    "j = 0\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "comp = []\n",
    "pbar = ProgressBar(widgets=[Percentage(), Bar(), ETA()], maxval=len(article_df)).start()\n",
    "for article in articles:\n",
    "    article_sentence = ' '.join(word for word in article)\n",
    "    ss = sid.polarity_scores(article_sentence)\n",
    "    pos.append(ss['pos'])\n",
    "    neg.append(ss['neg'])\n",
    "    neu.append(ss['neu'])\n",
    "    comp.append(ss['compound'])\n",
    "    pbar.update(i+1)\n",
    "    j += 1\n",
    "    if j%5000 == 0:\n",
    "        slack.SlackNotification('datacup', '%s / %s articles have been analyzed for sentiment.' % (j, len(article_df)))\n",
    "pbar.finish()\n",
    "article_df['pos'] = pos\n",
    "article_df['neg'] = neg\n",
    "article_df['neu'] = neu\n",
    "article_df['compound'] = comp\n",
    "slack.SlackNotification('datacup', 'All sentiment has been analyzed using the NLTK vader sentiment analysis method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106081</td>\n",
       "      <td>Trump Supporter “Kicked Pregnant Muslim Woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129341</td>\n",
       "      <td>UW Facts and Figures – University of Wisconsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100963</td>\n",
       "      <td>Gun Control Advocates Target Peaceful Switzerl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12200</td>\n",
       "      <td>U.S. and Republic of Korea Conclude New Specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128496</td>\n",
       "      <td>Kremlin's persistent claim of “expected chemic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  106081  Trump Supporter “Kicked Pregnant Muslim Woman ...\n",
       "1  129341  UW Facts and Figures – University of Wisconsin...\n",
       "2  100963  Gun Control Advocates Target Peaceful Switzerl...\n",
       "3   12200  U.S. and Republic of Korea Conclude New Specia...\n",
       "4  128496  Kremlin's persistent claim of “expected chemic..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_article_profile = article_df_enriched.profile_report(style={'full_width':True})\n",
    "enriched_article_profile.to_file(output_file=\"data_profiles/enriched_article_data_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'article_df_enriched' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Store article_df_enriched for loading in Model Development\n",
    "article_df_enriched = article_df\n",
    "%store article_df_enriched "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training data preparation\n",
    "\n",
    "Here we will summarize the article data for each claim, building the training data for model development. \n",
    "Summary statistics include mean, variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.json\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame.from_records(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td></td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...                    \n",
       "1  Maine legislature candidate Leslie Gibson insu...                    \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...                    \n",
       "3  In 1988 author Roald Dahl penned an open lette...                    \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0  \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1  \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4  \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5  \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "mean_pos = []\n",
    "mean_neg = []\n",
    "mean_neu = []\n",
    "mean_comp = []\n",
    "mean_brevity = []\n",
    "var_pos = []\n",
    "var_neg = []\n",
    "var_neu = []\n",
    "var_comp = []\n",
    "var_brevity = []\n",
    "for i, (claim) in enumerate(zip(train_df.related_articles)):\n",
    "    brevity = np.zeros([len(claim[0]), 1])\n",
    "    pos = np.zeros([len(claim[0]), 1])\n",
    "    neg = np.zeros([len(claim[0]), 1])\n",
    "    neu = np.zeros([len(claim[0]), 1])\n",
    "    comp = np.zeros([len(claim[0]), 1])\n",
    "    for k, article_id in enumerate(claim[0]):\n",
    "        target = article_df_enriched.loc[article_df_enriched['id'] == article_id]\n",
    "        if target.empty:\n",
    "            continue\n",
    "        brevity[k-1, 0] = target['brevity_score'].values\n",
    "        pos[k-1, 0] = target['pos'].values  \n",
    "        neg[k-1, 0] = target['neg'].values  \n",
    "        neu[k-1, 0] = target['neu'].values\n",
    "        comp[k-1, 0] = target['compound'].values    \n",
    "    mean_pos.append(np.mean(pos))\n",
    "    mean_neg.append(np.mean(neg))\n",
    "    mean_neu.append(np.mean(neu))\n",
    "    mean_comp.append(np.mean(comp))\n",
    "    mean_brevity.append(np.mean(brevity))\n",
    "    var_pos.append(np.var(pos))\n",
    "    var_neg.append(np.var(neg))\n",
    "    var_neu.append(np.var(neu))\n",
    "    var_comp.append(np.var(comp))\n",
    "    var_brevity.append(np.var(brevity))\n",
    "    j += 1\n",
    "    if j%5000 == 0:\n",
    "        slack.SlackNotification('BK_slackbot', '%s / %s claims data have been populated.' % (j, len(train_df)))\n",
    "#     if j == 2:\n",
    "#         break\n",
    "\n",
    "train_df['mean_pos'] = mean_pos\n",
    "train_df['mean_neg'] = mean_neg\n",
    "train_df['mean_neu'] = mean_neu\n",
    "train_df['mean_comp'] = mean_comp\n",
    "train_df['mean_brevity'] = mean_brevity\n",
    "\n",
    "train_df['var_pos'] = var_pos\n",
    "train_df['var_neg'] = var_neg\n",
    "train_df['var_neu'] = var_neu\n",
    "train_df['var_comp'] = var_comp\n",
    "train_df['var_brevity'] = var_brevity\n",
    "\n",
    "slack.SlackNotification('BK_slackbot', 'All claims data have been populated.')\n",
    "\n",
    "# def find_articles():\n",
    "#     df.loc[df['column_name'] == some_value]\n",
    "\n",
    "# def create_summary_stats(item):\n",
    "#     df.loc[df['column_name'] == some_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "      <th>mean_pos</th>\n",
       "      <th>mean_neg</th>\n",
       "      <th>mean_neu</th>\n",
       "      <th>mean_comp</th>\n",
       "      <th>mean_brevity</th>\n",
       "      <th>var_pos</th>\n",
       "      <th>var_neg</th>\n",
       "      <th>var_neu</th>\n",
       "      <th>var_comp</th>\n",
       "      <th>var_brevity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105750</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.566750</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.397071</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.112099</td>\n",
       "      <td>0.197894</td>\n",
       "      <td>0.053023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037667</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.311633</td>\n",
       "      <td>0.186249</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.194231</td>\n",
       "      <td>0.069377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.148667</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>0.217814</td>\n",
       "      <td>0.067672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td></td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.087333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>-0.666133</td>\n",
       "      <td>0.333458</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.107106</td>\n",
       "      <td>0.221867</td>\n",
       "      <td>0.055601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.095579</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.108536</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>0.045677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...                    \n",
       "1  Maine legislature candidate Leslie Gibson insu...                    \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...                    \n",
       "3  In 1988 author Roald Dahl penned an open lette...                    \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "         date  label                            related_articles  id  \\\n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0   \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1   \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4   \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5   \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6   \n",
       "\n",
       "   mean_pos  mean_neg  mean_neu  mean_comp  mean_brevity   var_pos   var_neg  \\\n",
       "0  0.105750  0.077500  0.566750   0.360500      0.397071  0.004667  0.003895   \n",
       "1  0.037667  0.014667  0.281000   0.311633      0.186249  0.002838  0.000430   \n",
       "2  0.148667  0.008667  0.509333   0.659933      0.358814  0.014507  0.000048   \n",
       "3  0.087333  0.117333  0.462000  -0.666133      0.333458  0.003830  0.007124   \n",
       "4  0.017167  0.002167  0.147333   0.154100      0.095579  0.001473  0.000023   \n",
       "\n",
       "    var_neu  var_comp  var_brevity  \n",
       "0  0.112099  0.197894     0.053023  \n",
       "1  0.157922  0.194231     0.069377  \n",
       "2  0.133561  0.217814     0.067672  \n",
       "3  0.107106  0.221867     0.055601  \n",
       "4  0.108536  0.118734     0.045677  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bking/virtualenvs/Fake_News_Data_Cup-bh3btNcR/lib/python3.7/site-packages/astropy/stats/bayesian_blocks.py:434: RuntimeWarning: divide by zero encountered in log\n",
      "  return N_k * (np.log(N_k) - np.log(T_k))\n"
     ]
    }
   ],
   "source": [
    "# Profile training data\n",
    "profile_train_df = train_df.profile_report(style={'full_width':True})\n",
    "profile_train_df.to_file(output_file=\"data_profiles/training_data_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fill out empty data for claimants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['claimant'].replace('', 'anon', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split data into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = train_df['label']\n",
    "features = train_df \\\n",
    "    .drop('claim', axis = 1) \\\n",
    "    .drop('label', axis = 1) \\\n",
    "    .drop('related_articles', axis = 1) \\\n",
    "    .drop('id', axis = 1) \\\n",
    "    .drop('date', axis = 1) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant</th>\n",
       "      <th>mean_pos</th>\n",
       "      <th>mean_neg</th>\n",
       "      <th>mean_neu</th>\n",
       "      <th>mean_comp</th>\n",
       "      <th>mean_brevity</th>\n",
       "      <th>var_pos</th>\n",
       "      <th>var_neg</th>\n",
       "      <th>var_neu</th>\n",
       "      <th>var_comp</th>\n",
       "      <th>var_brevity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon</td>\n",
       "      <td>0.105750</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.566750</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.397071</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.112099</td>\n",
       "      <td>0.197894</td>\n",
       "      <td>0.053023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon</td>\n",
       "      <td>0.037667</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.311633</td>\n",
       "      <td>0.186249</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.194231</td>\n",
       "      <td>0.069377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon</td>\n",
       "      <td>0.148667</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>0.217814</td>\n",
       "      <td>0.067672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon</td>\n",
       "      <td>0.087333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>-0.666133</td>\n",
       "      <td>0.333458</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.107106</td>\n",
       "      <td>0.221867</td>\n",
       "      <td>0.055601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.095579</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.108536</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>0.045677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          claimant  mean_pos  mean_neg  mean_neu  mean_comp  mean_brevity  \\\n",
       "0             anon  0.105750  0.077500  0.566750   0.360500      0.397071   \n",
       "1             anon  0.037667  0.014667  0.281000   0.311633      0.186249   \n",
       "2             anon  0.148667  0.008667  0.509333   0.659933      0.358814   \n",
       "3             anon  0.087333  0.117333  0.462000  -0.666133      0.333458   \n",
       "4  Hillary Clinton  0.017167  0.002167  0.147333   0.154100      0.095579   \n",
       "\n",
       "    var_pos   var_neg   var_neu  var_comp  var_brevity  \n",
       "0  0.004667  0.003895  0.112099  0.197894     0.053023  \n",
       "1  0.002838  0.000430  0.157922  0.194231     0.069377  \n",
       "2  0.014507  0.000048  0.133561  0.217814     0.067672  \n",
       "3  0.003830  0.007124  0.107106  0.221867     0.055601  \n",
       "4  0.001473  0.000023  0.108536  0.118734     0.045677  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Standardization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to encode claimant? High dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_claimant = features.drop('claimant', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing# Get column names first\n",
    "names = features_no_claimant.columns# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()# Fit your data on the scaler object\n",
    "scaled_features = scaler.fit_transform(features_no_claimant)\n",
    "scaled_features = pd.DataFrame(scaled_features, columns=names)\n",
    "\n",
    "# scaled_labels = scaler.fit_transform(labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split # Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(scaled_features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (11666, 10)\n",
      "Training Labels Shape: (11666,)\n",
      "Testing Features Shape: (3889, 10)\n",
      "Testing Labels Shape: (3889,)\n"
     ]
    }
   ],
   "source": [
    "# Make sure splitting was done right\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_features' (DataFrame)\n",
      "Stored 'test_features' (DataFrame)\n",
      "Stored 'train_labels' (Series)\n",
      "Stored 'test_labels' (Series)\n"
     ]
    }
   ],
   "source": [
    "# Store data for loading in Model Development\n",
    "%store train_features   \n",
    "%store test_features\n",
    "%store train_labels\n",
    "%store test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemma = set([wnl.lemmatize(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(tokens))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tags = nltk.pos_tag(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
